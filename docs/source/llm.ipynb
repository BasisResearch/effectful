{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import functools\n",
    "import inspect\n",
    "import logging\n",
    "import sys\n",
    "from collections.abc import Callable\n",
    "\n",
    "from effectful.handlers.llm import Template\n",
    "from effectful.handlers.llm.providers import (\n",
    "    CacheLLMRequestHandler,\n",
    "    LiteLLMProvider,\n",
    "    LLMLoggingHandler,\n",
    "    RetryLLMHandler,\n",
    "    completion,\n",
    "    tool_call,\n",
    ")\n",
    "from effectful.handlers.llm.synthesis import ProgramSynthesis\n",
    "from effectful.ops.semantics import NotHandled, fwd, handler\n",
    "from effectful.ops.syntax import defop\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e861b",
   "metadata": {},
   "source": [
    "## Interface\n",
    "\n",
    "The `robotl.ops.llm` module provides a simplified LLM interface that uses algebraic effects to provide modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `template` which creates a prompt template from a callable. We should think of the prompt template as an LLM-implemented function with behavior specified by a template string. When a templated function is called, an LLM is invoked to produce the specified behavior. The `__call__` method of a template is a handleable operation.\n",
    "- An operation `decode` which parses LLM output. `decode(t: type, c: str)` converts an LLM response `c` to the type `t`. It can be handled to provide decoding logic for particular types.\n",
    "- Interpretations for LLM providers `OpenAIIntp` and callable decoding `ProgramSynthesisIntp`. These interpretations can be composed to handle a variety of template behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There once was a fish in a brook,  \n",
      "Who fancied the way that he shook,  \n",
      "He'd wiggle and glide,  \n",
      "While swimming with pride,  \n",
      "And read tales in a watery nook.\n",
      "----------------------------------------\n",
      "There once was a fish in a brook,  \n",
      "Who fancied himself quite a cook.  \n",
      "With a splash and a wish,  \n",
      "He'd plate up a dish,  \n",
      "And read recipes from a book!  \n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or using `CacheLLMRequestHandler`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In cool water's flow,  \n",
      "Fish glide, silver scales shimmer,  \n",
      "Silent depths below.\n",
      "----------------------------------------\n",
      "In cool water's flow,  \n",
      "Fish glide, silver scales shimmer,  \n",
      "Silent depths below.\n",
      "\n",
      "Here's a haiku on the theme of fish2:\n",
      "\n",
      "Swimming in the sea,  \n",
      "Graceful fins beneath the tide,  \n",
      "Silent scales glide by.\n",
      "----------------------------------------\n",
      "Here's a haiku on the theme of fish2:\n",
      "\n",
      "Swimming in the sea,  \n",
      "Graceful fins beneath the tide,  \n",
      "Silent scales glide by.\n",
      "\n",
      "In the clear blue stream,  \n",
      "Silver scales flicker with light,  \n",
      "Gentle ripples dance.\n",
      "----------------------------------------\n",
      "In the clear blue stream,  \n",
      "Silver scales flicker with light,  \n",
      "Gentle ripples dance.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "cache_handler1 = CacheLLMRequestHandler()\n",
    "with handler(provider), handler(cache_handler1):\n",
    "    print(haiku_no_cache(\"fish2\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish2\"))\n",
    "\n",
    "print()\n",
    "cache_handler2 = CacheLLMRequestHandler()\n",
    "with handler(provider), handler(cache_handler2):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. `ProgramSynthesisIntp` provides a `decode` handler that parses Python callables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "litellm.APIConnectionError: APIConnectionError: OpenAIException - Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'type'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticInvalidForJsonSchema\u001b[39m              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/main.py:1327\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   1289\u001b[39m optional_param_args = {\n\u001b[32m   1290\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1291\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1325\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallowed_openai_params\u001b[39m\u001b[33m\"\u001b[39m: kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mallowed_openai_params\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1326\u001b[39m }\n\u001b[32m-> \u001b[39m\u001b[32m1327\u001b[39m optional_params = \u001b[43mget_optional_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptional_param_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnon_default_params\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1330\u001b[39m processed_non_default_params = pre_process_non_default_params(\n\u001b[32m   1331\u001b[39m     model=model,\n\u001b[32m   1332\u001b[39m     passed_params=optional_param_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1338\u001b[39m     provider_config=provider_config,\n\u001b[32m   1339\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/utils.py:3392\u001b[39m, in \u001b[36mget_optional_params\u001b[39m\u001b[34m(model, functions, function_call, temperature, top_p, n, stream, stream_options, stop, max_tokens, max_completion_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, custom_llm_provider, response_format, seed, tools, tool_choice, max_retries, logprobs, top_logprobs, extra_headers, api_version, parallel_tool_calls, drop_params, allowed_openai_params, reasoning_effort, verbosity, additional_drop_params, messages, thinking, web_search_options, safety_identifier, **kwargs)\u001b[39m\n\u001b[32m   3391\u001b[39m special_params = passed_params.pop(\u001b[33m\"\u001b[39m\u001b[33mkwargs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3392\u001b[39m non_default_params = \u001b[43mpre_process_non_default_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassed_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpassed_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspecial_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspecial_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3396\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_drop_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_drop_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3399\u001b[39m optional_params = pre_process_optional_params(\n\u001b[32m   3400\u001b[39m     passed_params=passed_params,\n\u001b[32m   3401\u001b[39m     non_default_params=non_default_params,\n\u001b[32m   3402\u001b[39m     custom_llm_provider=custom_llm_provider,\n\u001b[32m   3403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/utils.py:3196\u001b[39m, in \u001b[36mpre_process_non_default_params\u001b[39m\u001b[34m(passed_params, special_params, custom_llm_provider, additional_drop_params, model, remove_sensitive_keys, add_provider_specific_params, provider_config)\u001b[39m\n\u001b[32m   3195\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3196\u001b[39m         non_default_params[\u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mtype_to_response_format_param\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3197\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_default_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m non_default_params \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m   3201\u001b[39m     non_default_params, \u001b[38;5;28mlist\u001b[39m\n\u001b[32m   3202\u001b[39m ):  \u001b[38;5;66;03m# fixes https://github.com/BerriAI/litellm/issues/4933\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/llms/base_llm/base_utils.py:198\u001b[39m, in \u001b[36mtype_to_response_format_param\u001b[39m\u001b[34m(response_format, ref_template)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     schema = \u001b[43m_pydantic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_strict_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    201\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mjson_schema\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    202\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mjson_schema\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m    206\u001b[39m     },\n\u001b[32m    207\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/openai/lib/_pydantic.py:18\u001b[39m, in \u001b[36mto_strict_json_schema\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inspect.isclass(model) \u001b[38;5;129;01mand\u001b[39;00m is_basemodel_type(model):\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     schema = \u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m PYDANTIC_V1) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pydantic.TypeAdapter):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/openai/_compat.py:177\u001b[39m, in \u001b[36mmodel_json_schema\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model.schema()  \u001b[38;5;66;03m# pyright: ignore[reportDeprecated]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:576\u001b[39m, in \u001b[36mBaseModel.model_json_schema\u001b[39m\u001b[34m(cls, by_alias, ref_template, schema_generator, mode, union_format)\u001b[39m\n\u001b[32m    556\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates a JSON schema for a model class.\u001b[39;00m\n\u001b[32m    557\u001b[39m \n\u001b[32m    558\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    574\u001b[39m \u001b[33;03m    The JSON schema for the given model class.\u001b[39;00m\n\u001b[32m    575\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_json_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m=\u001b[49m\u001b[43mref_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43munion_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43munion_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema_generator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschema_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2542\u001b[39m, in \u001b[36mmodel_json_schema\u001b[39m\u001b[34m(cls, by_alias, ref_template, union_format, schema_generator, mode)\u001b[39m\n\u001b[32m   2541\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m.__pydantic_core_schema__, _mock_val_ser.MockCoreSchema), \u001b[33m'\u001b[39m\u001b[33mthis is a bug! please report it\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2542\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema_generator_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_core_schema__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:415\u001b[39m, in \u001b[36mGenerateJsonSchema.generate\u001b[39m\u001b[34m(self, schema, mode)\u001b[39m\n\u001b[32m    409\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    410\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThis JSON schema generator has already been used to generate a JSON schema. \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    411\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mYou must create a new instance of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to generate a new JSON schema.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    412\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mjson-schema-already-used\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    413\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m json_schema: JsonSchemaValue = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m json_ref_counts = \u001b[38;5;28mself\u001b[39m.get_json_ref_counts(json_schema)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:556\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.new_handler_func\u001b[39m\u001b[34m(schema_or_field, current_handler, js_modify_function)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_handler_func\u001b[39m(\n\u001b[32m    552\u001b[39m     schema_or_field: CoreSchemaOrField,\n\u001b[32m    553\u001b[39m     current_handler: GetJsonSchemaHandler = current_handler,\n\u001b[32m    554\u001b[39m     js_modify_function: GetJsonSchemaFunction = js_modify_function,\n\u001b[32m    555\u001b[39m ) -> JsonSchemaValue:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     json_schema = \u001b[43mjs_modify_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema_or_field):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:852\u001b[39m, in \u001b[36mBaseModel.__get_pydantic_json_schema__\u001b[39m\u001b[34m(cls, core_schema, handler)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook into generating the model's JSON schema.\u001b[39;00m\n\u001b[32m    836\u001b[39m \n\u001b[32m    837\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    850\u001b[39m \u001b[33;03m    A JSON schema, as a Python object.\u001b[39;00m\n\u001b[32m    851\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1604\u001b[39m, in \u001b[36mGenerateJsonSchema.model_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_wrapper_stack.push(config):\n\u001b[32m-> \u001b[39m\u001b[32m1604\u001b[39m     json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[38;5;28mself\u001b[39m._update_class_schema(json_schema, \u001b[38;5;28mcls\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1717\u001b[39m, in \u001b[36mGenerateJsonSchema.model_fields_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1716\u001b[39m     named_required_fields.extend(\u001b[38;5;28mself\u001b[39m._name_required_computed_fields(schema.get(\u001b[33m'\u001b[39m\u001b[33mcomputed_fields\u001b[39m\u001b[33m'\u001b[39m, [])))\n\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_named_required_fields_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamed_required_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1718\u001b[39m extras_schema = schema.get(\u001b[33m'\u001b[39m\u001b[33mextras_schema\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1508\u001b[39m, in \u001b[36mGenerateJsonSchema._named_required_fields_schema\u001b[39m\u001b[34m(self, named_required_fields)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m     field_json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m.copy()\n\u001b[32m   1509\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticOmit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1576\u001b[39m, in \u001b[36mGenerateJsonSchema.model_field_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1568\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates a JSON schema that matches a schema that defines a model field.\u001b[39;00m\n\u001b[32m   1569\u001b[39m \n\u001b[32m   1570\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1574\u001b[39m \u001b[33;03m    The generated JSON schema.\u001b[39;00m\n\u001b[32m   1575\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:556\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.new_handler_func\u001b[39m\u001b[34m(schema_or_field, current_handler, js_modify_function)\u001b[39m\n\u001b[32m    551\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_handler_func\u001b[39m(\n\u001b[32m    552\u001b[39m     schema_or_field: CoreSchemaOrField,\n\u001b[32m    553\u001b[39m     current_handler: GetJsonSchemaHandler = current_handler,\n\u001b[32m    554\u001b[39m     js_modify_function: GetJsonSchemaFunction = js_modify_function,\n\u001b[32m    555\u001b[39m ) -> JsonSchemaValue:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     json_schema = \u001b[43mjs_modify_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_handler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema_or_field):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:852\u001b[39m, in \u001b[36mBaseModel.__get_pydantic_json_schema__\u001b[39m\u001b[34m(cls, core_schema, handler)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Hook into generating the model's JSON schema.\u001b[39;00m\n\u001b[32m    836\u001b[39m \n\u001b[32m    837\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    850\u001b[39m \u001b[33;03m    A JSON schema, as a Python object.\u001b[39;00m\n\u001b[32m    851\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m852\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1604\u001b[39m, in \u001b[36mGenerateJsonSchema.model_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._config_wrapper_stack.push(config):\n\u001b[32m-> \u001b[39m\u001b[32m1604\u001b[39m     json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1606\u001b[39m \u001b[38;5;28mself\u001b[39m._update_class_schema(json_schema, \u001b[38;5;28mcls\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1717\u001b[39m, in \u001b[36mGenerateJsonSchema.model_fields_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1716\u001b[39m     named_required_fields.extend(\u001b[38;5;28mself\u001b[39m._name_required_computed_fields(schema.get(\u001b[33m'\u001b[39m\u001b[33mcomputed_fields\u001b[39m\u001b[33m'\u001b[39m, [])))\n\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_named_required_fields_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamed_required_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1718\u001b[39m extras_schema = schema.get(\u001b[33m'\u001b[39m\u001b[33mextras_schema\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1508\u001b[39m, in \u001b[36mGenerateJsonSchema._named_required_fields_schema\u001b[39m\u001b[34m(self, named_required_fields)\u001b[39m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m     field_json_schema = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m)\u001b[49m.copy()\n\u001b[32m   1509\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticOmit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:1576\u001b[39m, in \u001b[36mGenerateJsonSchema.model_field_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   1568\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates a JSON schema that matches a schema that defines a model field.\u001b[39;00m\n\u001b[32m   1569\u001b[39m \n\u001b[32m   1570\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1574\u001b[39m \u001b[33;03m    The generated JSON schema.\u001b[39;00m\n\u001b[32m   1575\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2009\u001b[39m, in \u001b[36mGenerateJsonSchema.custom_error_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generates a JSON schema that matches a schema that defines a custom error.\u001b[39;00m\n\u001b[32m   2002\u001b[39m \n\u001b[32m   2003\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2007\u001b[39m \u001b[33;03m    The generated JSON schema.\u001b[39;00m\n\u001b[32m   2008\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2009\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mschema\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:578\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    576\u001b[39m     current_handler = _schema_generation_shared.GenerateJsonSchemaHandler(\u001b[38;5;28mself\u001b[39m, new_handler_func)\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m json_schema = \u001b[43mcurrent_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _core_utils.is_core_schema(schema):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/_internal/_schema_generation_shared.py:37\u001b[39m, in \u001b[36mGenerateJsonSchemaHandler.__call__\u001b[39m\u001b[34m(self, core_schema)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, core_schema: CoreSchemaOrField, /) -> JsonSchemaValue:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:511\u001b[39m, in \u001b[36mGenerateJsonSchema.generate_inner.<locals>.handler_func\u001b[39m\u001b[34m(schema_or_field)\u001b[39m\n\u001b[32m    510\u001b[39m     generate_for_schema_type = \u001b[38;5;28mself\u001b[39m._schema_type_to_method[schema_or_field[\u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m     json_schema = \u001b[43mgenerate_for_schema_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema_or_field\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:921\u001b[39m, in \u001b[36mGenerateJsonSchema.is_instance_schema\u001b[39m\u001b[34m(self, schema)\u001b[39m\n\u001b[32m    911\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Handles JSON schema generation for a core schema that checks if a value is an instance of a class.\u001b[39;00m\n\u001b[32m    912\u001b[39m \n\u001b[32m    913\u001b[39m \u001b[33;03mUnless overridden in a subclass, this raises an error.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    919\u001b[39m \u001b[33;03m    The generated JSON schema.\u001b[39;00m\n\u001b[32m    920\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_invalid_for_json_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcore_schema.IsInstanceSchema (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mschema\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m)\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2436\u001b[39m, in \u001b[36mGenerateJsonSchema.handle_invalid_for_json_schema\u001b[39m\u001b[34m(self, schema, error_info)\u001b[39m\n\u001b[32m   2435\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandle_invalid_for_json_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, schema: CoreSchemaOrField, error_info: \u001b[38;5;28mstr\u001b[39m) -> JsonSchemaValue:\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticInvalidForJsonSchema(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mCannot generate a JsonSchema for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mPydanticInvalidForJsonSchema\u001b[39m: Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'type'>)\n\nFor further information visit https://errors.pydantic.dev/2.12/u/invalid-for-json-schema",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotHandled\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m handler(provider), handler(ProgramSynthesis()):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     count_a = \u001b[43mcount_char\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(count_a)\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m count_a(\u001b[33m\"\u001b[39m\u001b[33mbanana\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[32m3\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:490\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__apply__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:488\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m self_handler(*args, **kwargs)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__default__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__apply__(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:539\u001b[39m, in \u001b[36m__apply__\u001b[39m\u001b[34m(op, *args, **kwargs)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__apply__\u001b[39m[**A, B](op: Operation[A, B], *args: A.args, **kwargs: A.kwargs) -> B:\n\u001b[32m    511\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply ``op`` to ``args``, ``kwargs`` in interpretation ``intp``.\u001b[39;00m\n\u001b[32m    512\u001b[39m \n\u001b[32m    513\u001b[39m \u001b[33;03m    Handling :func:`Operation.__apply__` changes the evaluation strategy of terms.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m \n\u001b[32m    538\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__default_rule__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:335\u001b[39m, in \u001b[36mOperation.__default_rule__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__default__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    337\u001b[39m         warnings.warn(\n\u001b[32m    338\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOperations should raise effectful.ops.types.NotHandled instead of NotImplementedError.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    340\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:451\u001b[39m, in \u001b[36mOperation.__get__.<locals>._instance_op\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_instance_op\u001b[39m(instance, *args, **kwargs):\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meffectful\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msyntax\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defdata\n\u001b[32m--> \u001b[39m\u001b[32m451\u001b[39m     default_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    452\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    453\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(default_result, Term)\n\u001b[32m    454\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m default_result.op \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    460\u001b[39m         \u001b[38;5;66;03m#   so that the instance-specific operation reappears\u001b[39;00m\n\u001b[32m    461\u001b[39m         \u001b[38;5;66;03m#   in the final term and is therefore visible to evaluate()\u001b[39;00m\n\u001b[32m    462\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m defdata(\n\u001b[32m    463\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__get__\u001b[39m(default_result.args[\u001b[32m0\u001b[39m]),\n\u001b[32m    464\u001b[39m             *default_result.args[\u001b[32m1\u001b[39m:],\n\u001b[32m    465\u001b[39m             **default_result.kwargs,\n\u001b[32m    466\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:485\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m self_handler = intp.get(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m self_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:70\u001b[39m, in \u001b[36m_set_prompt.<locals>.bound_body\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     68\u001b[39m next_cont = get_interpretation().get(prompt, prompt.__default_rule__)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m handler({prompt: handler({prompt: next_cont})(cont)}):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:56\u001b[39m, in \u001b[36m_save_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m handler({_get_args: \u001b[38;5;28;01mlambda\u001b[39;00m: (a, k)}):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/handlers/llm/synthesis.py:363\u001b[39m, in \u001b[36mProgramSynthesis._call\u001b[39m\u001b[34m(self, template, *args, **kwargs)\u001b[39m\n\u001b[32m    340\u001b[39m         context_section = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    341\u001b[39m \u001b[33mThe following types, functions, and values are available:\u001b[39m\n\u001b[32m    342\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    345\u001b[39m \u001b[33m```\u001b[39m\n\u001b[32m    346\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    348\u001b[39m         prompt_ext = textwrap.dedent(\u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[33m        Implement a Python function with the following specification.\u001b[39m\n\u001b[32m    350\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    360\u001b[39m \u001b[33m        5. Do not include import statements.\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m).strip()\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         response: SynthesizedFunction = \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataclasses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m                \u001b[49m\u001b[43m__prompt_template__\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_ext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m                \u001b[49m\u001b[43m__signature__\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__signature__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mreturn_annotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSynthesizedFunction\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    375\u001b[39m         \u001b[38;5;66;03m# Build and return the function using lexical context for exec globals\u001b[39;00m\n\u001b[32m    376\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_function(response, ret_type, template.__context__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:485\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m self_handler = intp.get(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m self_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:45\u001b[39m, in \u001b[36m_restore_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     44\u001b[39m     a, k = (a, k) \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;28;01melse\u001b[39;00m _get_args()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:56\u001b[39m, in \u001b[36m_save_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m handler({_get_args: \u001b[38;5;28;01mlambda\u001b[39;00m: (a, k)}):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:70\u001b[39m, in \u001b[36m_set_prompt.<locals>.bound_body\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     68\u001b[39m next_cont = get_interpretation().get(prompt, prompt.__default_rule__)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m handler({prompt: handler({prompt: next_cont})(cont)}):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:56\u001b[39m, in \u001b[36m_save_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m handler({_get_args: \u001b[38;5;28;01mlambda\u001b[39;00m: (a, k)}):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/handlers/llm/providers.py:490\u001b[39m, in \u001b[36mLiteLLMProvider._call\u001b[39m\u001b[34m(self, template, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m \u001b[38;5;129m@implements\u001b[39m(Template.\u001b[34m__call__\u001b[39m)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call\u001b[39m[**P, T](\n\u001b[32m    487\u001b[39m     \u001b[38;5;28mself\u001b[39m, template: Template[P, T], *args: P.args, **kwargs: P.kwargs\n\u001b[32m    488\u001b[39m ) -> T:\n\u001b[32m    489\u001b[39m     model_input = format_model_input(template, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     resp = \u001b[43mcompute_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m decode_response(template, resp)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:490\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__apply__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:488\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m self_handler(*args, **kwargs)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__default__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__apply__(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:539\u001b[39m, in \u001b[36m__apply__\u001b[39m\u001b[34m(op, *args, **kwargs)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__apply__\u001b[39m[**A, B](op: Operation[A, B], *args: A.args, **kwargs: A.kwargs) -> B:\n\u001b[32m    511\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Apply ``op`` to ``args``, ``kwargs`` in interpretation ``intp``.\u001b[39;00m\n\u001b[32m    512\u001b[39m \n\u001b[32m    513\u001b[39m \u001b[33;03m    Handling :func:`Operation.__apply__` changes the evaluation strategy of terms.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    537\u001b[39m \n\u001b[32m    538\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__default_rule__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:335\u001b[39m, in \u001b[36mOperation.__default_rule__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__default__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    337\u001b[39m         warnings.warn(\n\u001b[32m    338\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOperations should raise effectful.ops.types.NotHandled instead of NotImplementedError.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    340\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/handlers/llm/providers.py:386\u001b[39m, in \u001b[36mcompute_response\u001b[39m\u001b[34m(template, model_input)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;66;03m# loop based on: https://cookbook.openai.com/examples/reasoning_function_calls\u001b[39;00m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m386\u001b[39m     response: ModelResponse = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpydantic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mResponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_encoding_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__config__\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mextra\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforbid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_encoding_type\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtool_schemas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     choice: Choices = typing.cast(Choices, response.choices[\u001b[32m0\u001b[39m])\n\u001b[32m    397\u001b[39m     message: Message = choice.message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:485\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m self_handler = intp.get(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m self_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:70\u001b[39m, in \u001b[36m_set_prompt.<locals>.bound_body\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     68\u001b[39m next_cont = get_interpretation().get(prompt, prompt.__default_rule__)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m handler({prompt: handler({prompt: next_cont})(cont)}):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:56\u001b[39m, in \u001b[36m_save_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m handler({_get_args: \u001b[38;5;28;01mlambda\u001b[39;00m: (a, k)}):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/handlers/llm/providers.py:483\u001b[39m, in \u001b[36mLiteLLMProvider._completion\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m \u001b[38;5;129m@implements\u001b[39m(completion)\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_completion\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[43m|\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:485\u001b[39m, in \u001b[36mOperation.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m self_handler = intp.get(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m self_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[32m0\u001b[39m], Operation) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m args[\u001b[32m0\u001b[39m].__apply__:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Prevent infinite recursion when calling self.apply directly\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__default__(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:45\u001b[39m, in \u001b[36m_restore_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     44\u001b[39m     a, k = (a, k) \u001b[38;5;28;01mif\u001b[39;00m a \u001b[38;5;129;01mor\u001b[39;00m k \u001b[38;5;28;01melse\u001b[39;00m _get_args()\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/internals/runtime.py:56\u001b[39m, in \u001b[36m_save_args.<locals>._cont_wrapper\u001b[39m\u001b[34m(*a, **k)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_cont_wrapper\u001b[39m(*a: P.args, **k: P.kwargs) -> T:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m handler({_get_args: \u001b[38;5;28;01mlambda\u001b[39;00m: (a, k)}):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/ops/types.py:335\u001b[39m, in \u001b[36mOperation.__default_rule__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    334\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__default__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[32m    337\u001b[39m         warnings.warn(\n\u001b[32m    338\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mOperations should raise effectful.ops.types.NotHandled instead of NotImplementedError.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m    340\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/effectful/handlers/llm/providers.py:225\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    221\u001b[39m \u001b[38;5;129m@defop\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(litellm.completion)\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompletion\u001b[39m(*args, **kwargs) -> Any:\n\u001b[32m    224\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Low-level LLM request. Handlers may log/modify requests and delegate via fwd().\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/utils.py:1382\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1379\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1380\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1381\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/utils.py:1251\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1249\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1250\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1254\u001b[39m     kwargs=kwargs,\n\u001b[32m   1255\u001b[39m     call_type=call_type,\n\u001b[32m   1256\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/main.py:3842\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   3839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3840\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3841\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3842\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3845\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2333\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2331\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, error_type):\n\u001b[32m   2332\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2333\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e  \u001b[38;5;66;03m# it's already mapped\u001b[39;00m\n\u001b[32m   2334\u001b[39m raised_exc = APIConnectionError(\n\u001b[32m   2335\u001b[39m     message=\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(original_exception, traceback.format_exc()),\n\u001b[32m   2336\u001b[39m     llm_provider=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2337\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2338\u001b[39m )\n\u001b[32m   2339\u001b[39m \u001b[38;5;28msetattr\u001b[39m(raised_exc, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Marc/effectful/.venv/lib/python3.12/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:574\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    563\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m APIError(\n\u001b[32m    564\u001b[39m                 status_code=original_exception.status_code,\n\u001b[32m    565\u001b[39m                 message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPIError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    569\u001b[39m                 litellm_debug_info=extra_information,\n\u001b[32m    570\u001b[39m             )\n\u001b[32m    571\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    572\u001b[39m         \u001b[38;5;66;03m# if no status code then it is an APIConnectionError: https://github.com/openai/openai-python#handling-errors\u001b[39;00m\n\u001b[32m    573\u001b[39m         \u001b[38;5;66;03m# exception_mapping_worked = True\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(\n\u001b[32m    575\u001b[39m             message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPIConnectionError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    576\u001b[39m             llm_provider=custom_llm_provider,\n\u001b[32m    577\u001b[39m             model=model,\n\u001b[32m    578\u001b[39m             litellm_debug_info=extra_information,\n\u001b[32m    579\u001b[39m             request=httpx.Request(\n\u001b[32m    580\u001b[39m                 method=\u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m, url=\u001b[33m\"\u001b[39m\u001b[33mhttps://api.openai.com/v1/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    581\u001b[39m             ),\n\u001b[32m    582\u001b[39m         )\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    584\u001b[39m     custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33manthropic\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    585\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m custom_llm_provider == \u001b[33m\"\u001b[39m\u001b[33manthropic_text\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    586\u001b[39m ):  \u001b[38;5;66;03m# one of the anthropics\u001b[39;00m\n\u001b[32m    587\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprompt is too long\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprompt: length\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n",
      "\u001b[31mAPIConnectionError\u001b[39m: litellm.APIConnectionError: APIConnectionError: OpenAIException - Cannot generate a JsonSchema for core_schema.IsInstanceSchema (<class 'type'>)"
     ]
    }
   ],
   "source": [
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider), handler(ProgramSynthesis()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call: cities(*(), **{}) -> ['Chicago', 'New York', 'Barcelona']\n",
      "Tool call: weather(*(), **{'city': 'Chicago'}) -> cold\n",
      "Tool call: weather(*(), **{'city': 'New York'}) -> wet\n",
      "Tool call: weather(*(), **{'city': 'Barcelona'}) -> sunny\n",
      "Among the cities checked, Barcelona has good weather, as it is currently sunny.\n"
     ]
    }
   ],
   "source": [
    "@defop\n",
    "def cities() -> list[str]:\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@defop\n",
    "def weather(city: str) -> str:\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def log_tool_call(_, tool, *args, **kwargs):\n",
    "    result = fwd()\n",
    "    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "with handler(provider), handler({tool_call: log_tool_call}):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Liz.\n",
      "Liz who?\n",
      "Liz-ard you curious who's at the door?\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cab62b5",
   "metadata": {},
   "source": [
    "### Logging LLM requests\n",
    "To intercept messages being called on the lower-level, we can write a handler for `completion`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf495a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request fired:  () {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a haiku on the theme of fish2. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]} ModelResponse(id='chatcmpl-CnANzyeB958opw15SxIJ5GLG5eCI8', created=1765834031, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In the gentle stream,  \\nSilver scales shimmer and dance,  \\nQuietly they glide.  ', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=20, prompt_tokens=364, total_tokens=384, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n",
      "Request fired:  () {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a limerick on the theme of fish. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]} ModelResponse(id='chatcmpl-CnAO05Uemhl4BA8dIUcQyqoKIyOvk', created=1765834032, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In the sea where the waves gently swish,  \\nLived a fish with a hopeful wish.  \\nHe dreamed of the skies,  \\nTo soar and to rise,  \\nBut alas, he remained just a fish.  ', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=46, prompt_tokens=364, total_tokens=410, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')\n"
     ]
    }
   ],
   "source": [
    "def log_llm(*args, **kwargs):\n",
    "    result = fwd()\n",
    "    print(\"Request fired: \", args, kwargs, result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# Avoid cache\n",
    "try:\n",
    "    haiku.cache_clear()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Put completion handler innermost so it has highest precedence during the call\n",
    "with handler(provider), handler({completion: log_llm}):\n",
    "    _ = haiku(\"fish2\")\n",
    "    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e531d",
   "metadata": {},
   "source": [
    "### Python logging for LLM requests and tool calls\n",
    "We can also uses Python logger through `LLMLoggingHandler` to log both low-level LLM requests (`completion`) and model-initiated tool use (`tool_call`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a15f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a haiku on the theme of fish3. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOCov9x47s8Jj0K2oGyrB21h9dM', created=1765834044, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"theme\":\"fish\"}', name='haiku_no_cache'), id='call_8gQN3B78H2aZzIdOZPhEqPqy', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=17, prompt_tokens=364, total_tokens=381, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a haiku on the theme of fish. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOD4UrpELPotqSt3s76CnJGu6FB', created=1765834045, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In the quiet stream,  \\nSilver scales shimmer with grace,  \\nFish dance in moonlight.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=20, prompt_tokens=363, total_tokens=383, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'haiku_no_cache', 'args': (), 'kwargs': {'theme': 'fish'}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a haiku on the theme of fish3. Do not use any tools.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{\"theme\":\"fish\"}', 'name': 'haiku_no_cache'}, 'id': 'call_8gQN3B78H2aZzIdOZPhEqPqy', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_8gQN3B78H2aZzIdOZPhEqPqy', 'name': 'haiku_no_cache', 'content': [{'type': 'text', 'text': 'In the quiet stream,  \\nSilver scales shimmer with grace,  \\nFish dance in moonlight.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOEXNCJJEDIOBwwR8PaKYXoqOCs', created=1765834046, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In the quiet stream,  \\nSilver scales shimmer with grace,  \\nFish dance in moonlight.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=20, prompt_tokens=410, total_tokens=430, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a limerick on the theme of fish4. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOEfHrN8jTkm6tIJ7EzgXP9bo2d', created=1765834046, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=45, prompt_tokens=365, total_tokens=410, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n"
     ]
    }
   ],
   "source": [
    "# 1. Create a logger\n",
    "logger = logging.getLogger(\"effectful.llm\")\n",
    "logger.setLevel(logging.INFO)\n",
    "log_handler = logging.StreamHandler(sys.stdout)\n",
    "log_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\n",
    "logger.addHandler(log_handler)\n",
    "# 2. Pass it to the handler\n",
    "llm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\n",
    "\n",
    "# Avoid cache for demonstration\n",
    "try:\n",
    "    haiku.cache_clear()\n",
    "    limerick.cache_clear()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "with handler(provider), handler(llm_logger):\n",
    "    _ = haiku(\"fish3\")\n",
    "    _ = limerick(\"fish4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: [Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': ..., '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': ..., '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='limerick'), Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': ..., 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': ..., 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='haiku_no_cache'), Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': ..., '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': ..., '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='primes'), Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': ..., 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': ..., 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='count_char'), Operation(cities, () -> list[str]), Operation(weather, (city: str) -> str), Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': ..., 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': ..., 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='vacation'), Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': ..., 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': ..., 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='write_joke'), Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': ..., 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': ..., 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='rate_joke'), Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': ..., 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': ..., 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='story_with_moral'), Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': ..., 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': ..., 'write_story': Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_story')})), __name__='story_funny'), Template(__prompt_template__=\"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", __signature__=<Signature (topic: str, style: str) -> str>, __context__=LexicalContext(mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': ...}), mappingproxy({'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], '_oh': {}, '_dh': [PosixPath('/Users/datnguyenthanh/Marc/effectful')], 'In': ['', 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))'], 'Out': {}, 'get_ipython': <bound method InteractiveShell.get_ipython of <ipykernel.zmqshell.ZMQInteractiveShell object at 0x109130290>>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x10995ca10>, 'open': <function open at 0x1044a5f80>, '_': 'In the ocean where fishies do play,  \\nA big whale came swimming one day.  \\nWith a splash and a dive,  \\nHe felt so alive,  \\nChasing fish in the blue, gleaming bay.', '__': '', '___': '', '__vsc_ipynb_file__': '/Users/datnguyenthanh/Marc/effectful/docs/source/llm.ipynb', '_i': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', '_ii': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', '_iii': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', '_i1': 'import dataclasses\\nimport functools\\nimport inspect\\nimport logging\\nimport sys\\nfrom collections.abc import Callable\\n\\nfrom effectful.handlers.llm import Template\\nfrom effectful.handlers.llm.providers import (\\n    CacheLLMRequestHandler,\\n    LiteLLMProvider,\\n    LLMLoggingHandler,\\n    RetryLLMHandler,\\n    completion,\\n    tool_call,\\n)\\nfrom effectful.handlers.llm.synthesis import ProgramSynthesis\\nfrom effectful.ops.semantics import NotHandled, fwd, handler\\nfrom effectful.ops.syntax import defop\\n\\nprovider = LiteLLMProvider()', 'dataclasses': <module 'dataclasses' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/dataclasses.py'>, 'functools': <module 'functools' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/functools.py'>, 'inspect': <module 'inspect' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/inspect.py'>, 'logging': <module 'logging' from '/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/logging/__init__.py'>, 'sys': <module 'sys' (built-in)>, 'Callable': <class 'collections.abc.Callable'>, 'Template': <class 'effectful.handlers.llm.Template'>, 'CacheLLMRequestHandler': <class 'effectful.handlers.llm.providers.CacheLLMRequestHandler'>, 'LiteLLMProvider': <class 'effectful.handlers.llm.providers.LiteLLMProvider'>, 'LLMLoggingHandler': <class 'effectful.handlers.llm.providers.LLMLoggingHandler'>, 'RetryLLMHandler': <class 'effectful.handlers.llm.providers.RetryLLMHandler'>, 'completion': Operation(completion, (model: str, messages: List = [], timeout: Union[float, str, openai.Timeout, NoneType] = None, temperature: Optional[float] = None, top_p: Optional[float] = None, n: Optional[int] = None, stream: Optional[bool] = None, stream_options: Optional[dict] = None, stop=None, max_completion_tokens: Optional[int] = None, max_tokens: Optional[int] = None, modalities: Optional[List[Literal['text', 'audio']]] = None, prediction: Optional[openai.types.chat.chat_completion_prediction_content_param.ChatCompletionPredictionContentParam] = None, audio: Optional[openai.types.chat.chat_completion_audio_param.ChatCompletionAudioParam] = None, presence_penalty: Optional[float] = None, frequency_penalty: Optional[float] = None, logit_bias: Optional[dict] = None, user: Optional[str] = None, reasoning_effort: Optional[Literal['none', 'minimal', 'low', 'medium', 'high', 'default']] = None, verbosity: Optional[Literal['low', 'medium', 'high']] = None, response_format: Union[dict, Type[pydantic.main.BaseModel], NoneType] = None, seed: Optional[int] = None, tools: Optional[List] = None, tool_choice: Union[str, dict, NoneType] = None, logprobs: Optional[bool] = None, top_logprobs: Optional[int] = None, parallel_tool_calls: Optional[bool] = None, web_search_options: Optional[litellm.types.llms.openai.OpenAIWebSearchOptions] = None, deployment_id=None, extra_headers: Optional[dict] = None, safety_identifier: Optional[str] = None, service_tier: Optional[str] = None, functions: Optional[List] = None, function_call: Optional[str] = None, base_url: Optional[str] = None, api_version: Optional[str] = None, api_key: Optional[str] = None, model_list: Optional[list] = None, thinking: Optional[litellm.types.llms.anthropic.AnthropicThinkingParam] = None, shared_session: Optional[ForwardRef('ClientSession')] = None, **kwargs) -> Union[litellm.types.utils.ModelResponse, litellm.litellm_core_utils.streaming_handler.CustomStreamWrapper]), 'tool_call': Operation(tool_call, (template: effectful.handlers.llm.Template, tool: Union[effectful.ops.types.Operation[..., T], effectful.handlers.llm.Template[..., T]], *args, **kwargs) -> T), 'ProgramSynthesis': <class 'effectful.handlers.llm.synthesis.ProgramSynthesis'>, 'NotHandled': <class 'effectful.ops.types.NotHandled'>, 'fwd': Operation(fwd, (*args, **kwargs) -> Any), 'handler': <function handler at 0x109f71800>, 'defop': <function Operation.define at 0x10999efc0>, 'provider': <effectful.handlers.llm.providers.LiteLLMProvider object at 0x1099c0b90>, '_i2': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}.\"\"\"\\n    raise NotHandled', 'limerick': Template(__prompt_template__='Write a limerick on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='limerick'), '_i3': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i4': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i5': '@Template.define\\ndef limerick(theme: str) -> str:\\n    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled', '_i6': 'with handler(provider):\\n    print(limerick(\"fish\"))\\n    print(\"-\" * 40)\\n    print(limerick(\"fish\"))', '_i7': '@functools.cache\\n@Template.define\\ndef haiku(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef haiku_no_cache(theme: str) -> str:\\n    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nprint()\\nwith handler(provider):\\n    print(haiku(\"fish\"))\\n    print(\"-\" * 40)\\n    print(haiku(\"fish\"))\\n\\nprint()\\ncache_handler1 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler1):\\n    print(haiku_no_cache(\"fish2\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish2\"))\\n\\nprint()\\ncache_handler2 = CacheLLMRequestHandler()\\nwith handler(provider), handler(cache_handler2):\\n    print(haiku_no_cache(\"fish3\"))\\n    print(\"-\" * 40)\\n    print(haiku_no_cache(\"fish3\"))', 'haiku': <functools._lru_cache_wrapper object at 0x12bf35f30>, 'haiku_no_cache': Template(__prompt_template__='Write a haiku on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='haiku_no_cache'), 'cache_handler1': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b8c0110>, 'cache_handler2': <effectful.handlers.llm.providers.CacheLLMRequestHandler object at 0x12b9f78f0>, '_i8': '@Template.define\\ndef primes(first_digit: int) -> int:\\n    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider):\\n    assert type(primes(6)) is int', 'primes': Template(__prompt_template__='Give a prime number with {first_digit} as the first digit. Do not use any tools.', __signature__=<Signature (first_digit: int) -> int>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='primes'), '_i9': '@Template.define\\ndef count_char(char: str) -> Callable[[str], int]:\\n    \"\"\"Write a function which takes a string and counts the occurrances of \\'{char}\\'. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\nwith handler(provider), handler(ProgramSynthesis()):\\n    count_a = count_char(\"a\")\\n    assert callable(count_a)\\n    assert count_a(\"banana\") == 3\\n    assert count_a(\"cherry\") == 0\\n    # Print the source code of the generated function\\n    print(inspect.getsource(count_a))', 'count_char': Template(__prompt_template__=\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", __signature__=<Signature (char: str) -> collections.abc.Callable[[str], int]>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='count_char'), 'count_a': <function count_a_occurrences at 0x12bf642c0>, '_i10': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', 'cities': Operation(cities, () -> list[str]), 'weather': Operation(weather, (city: str) -> str), 'vacation': Template(__prompt_template__='Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', __signature__=<Signature () -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='vacation'), 'log_tool_call': <function log_tool_call at 0x12bfa37e0>, '_i11': '@defop\\ndef cities() -> list[str]:\\n    return [\"Chicago\", \"New York\", \"Barcelona\"]\\n\\n\\n@defop\\ndef weather(city: str) -> str:\\n    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\\n    return status.get(city, \"unknown\")\\n\\n\\n@Template.define  # cities and weather auto-captured from lexical scope\\ndef vacation() -> str:\\n    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\\n    raise NotHandled\\n\\n\\ndef log_tool_call(_, tool, *args, **kwargs):\\n    result = fwd()\\n    print(f\"Tool call: {tool}(*{args}, **{kwargs}) -> {result}\")\\n    return result\\n\\n\\nwith handler(provider), handler({tool_call: log_tool_call}):\\n    print(vacation())', '_i12': '@dataclasses.dataclass\\nclass KnockKnockJoke:\\n    whos_there: str\\n    punchline: str\\n\\n\\n@Template.define\\ndef write_joke(theme: str) -> KnockKnockJoke:\\n    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef rate_joke(joke: KnockKnockJoke) -> bool:\\n    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\ndef do_comedy():\\n    joke = write_joke(\"lizards\")\\n    print(\"> You are onstage at a comedy club. You tell the following joke:\")\\n    print(\\n        f\"Knock knock.\\\\nWho\\'s there?\\\\n{joke.whos_there}.\\\\n{joke.whos_there} who?\\\\n{joke.punchline}\"\\n    )\\n    if rate_joke(joke):\\n        print(\"> The crowd laughs politely.\")\\n    else:\\n        print(\"> The crowd stares in stony silence.\")\\n\\n\\nwith handler(provider):\\n    do_comedy()', 'KnockKnockJoke': <class '__main__.KnockKnockJoke'>, 'write_joke': Template(__prompt_template__='Write a knock-knock joke on the theme of {theme}. Do not use any tools.', __signature__=<Signature (theme: str) -> __main__.KnockKnockJoke>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='write_joke'), 'rate_joke': Template(__prompt_template__='Decide if {joke} is funny or not. Do not use any tools.', __signature__=<Signature (joke: __main__.KnockKnockJoke) -> bool>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='rate_joke'), 'do_comedy': <function do_comedy at 0x12bfa3100>, '_i13': 'def log_llm(*args, **kwargs):\\n    result = fwd()\\n    print(\"Request fired: \", args, kwargs, result)\\n    return result\\n\\n\\n# Avoid cache\\ntry:\\n    haiku.cache_clear()\\nexcept Exception:\\n    pass\\n\\n# Put completion handler innermost so it has highest precedence during the call\\nwith handler(provider), handler({completion: log_llm}):\\n    _ = haiku(\"fish2\")\\n    _ = limerick(\"fish\")  # or use haiku(\"fish-2\") to avoid cache', 'log_llm': <function log_llm at 0x12c037f60>, '_i14': '# 1. Create a logger\\nlogger = logging.getLogger(\"effectful.llm\")\\nlogger.setLevel(logging.INFO)\\nlog_handler = logging.StreamHandler(sys.stdout)\\nlog_handler.setFormatter(logging.Formatter(\"%(levelname)s %(payload)s\"))\\nlogger.addHandler(log_handler)\\n# 2. Pass it to the handler\\nllm_logger = LLMLoggingHandler(logger=logger)  # can also be LLMLoggingHandler()\\n\\n# Avoid cache for demonstration\\ntry:\\n    haiku.cache_clear()\\n    limerick.cache_clear()\\nexcept Exception:\\n    pass\\n\\nwith handler(provider), handler(llm_logger):\\n    _ = haiku(\"fish3\")\\n    _ = limerick(\"fish4\")', 'logger': <Logger effectful.llm (INFO)>, 'log_handler': <StreamHandler stdout (NOTSET)>, 'llm_logger': <effectful.handlers.llm.providers.LLMLoggingHandler object at 0x12e131fd0>, '_i15': '# Sub-templates for different story styles\\n@Template.define\\ndef story_with_moral(topic: str) -> str:\\n    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n@Template.define\\ndef story_funny(topic: str) -> str:\\n    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\\n    raise NotHandled\\n\\n\\n# Main orchestrator template - has access to sub-templates\\n@Template.define\\ndef write_story(topic: str, style: str) -> str:\\n    \"\"\"Write a story about {topic} in the style: {style}.\\n    Available styles: \\'moral\\' for a story with a lesson, \\'funny\\' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\\n    raise NotHandled\\n\\n\\n# Verify sub-templates are captured in write_story\\'s lexical context\\nassert story_with_moral in write_story.tools\\nassert story_funny in write_story.tools\\nprint(\"Sub-templates available to write_story:\", list(write_story.tools))\\n\\nwith handler(provider), handler(llm_logger):\\n    print(\"=== Story with moral ===\")\\n    print(write_story(\"a curious cat\", \"moral\"))\\n    print()\\n    print(\"=== Funny story ===\")\\n    print(write_story(\"a curious cat\", \"funny\"))', 'story_with_moral': Template(__prompt_template__='Write a short story about {topic} and end with a moral lesson. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_with_moral'), 'story_funny': Template(__prompt_template__='Write a funny, humorous story about {topic}. Do not use any tools.', __signature__=<Signature (topic: str) -> str>, __context__=LexicalContext(mappingproxy({...}), mappingproxy({...})), __name__='story_funny'), 'write_story': ...})), __name__='write_story')]\n",
      "=== Story with moral ===\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': \"Write a story about a curious cat in the style: moral.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOJJzdrkeZmPdyh1h0cMSFZlFJE', created=1765834051, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"topic\":\"a curious cat\"}', name='story_with_moral'), id='call_nJMDv3AxDTvyxxoDKXAzH4aB', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=18, prompt_tokens=560, total_tokens=578, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a short story about a curious cat and end with a moral lesson. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOJnGjxZtPLcZ9ekNXtCUneEitd', created=1765834051, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='In a quaint village nestled between rolling hills and whispering streams, there lived a cat named Whiskers. Whiskers was not an ordinary cat; his sleek, shiny coat gleamed under the sun, and his eyes sparkled with a clever curiosity that set him apart. His inquisitive nature drove him to explore every nook and cranny of the village, always seeking new adventures.\\n\\nOne day, while wandering near the woods, Whiskers stumbled upon a mysterious path he had never seen before. The path was lined with wildflowers and arched by towering trees that seemed to stretch on forever. Intrigued, Whiskers decided to follow it to see where it would lead.\\n\\nThe further he ventured, the stranger the path became. He encountered bubbling brooks, frogs that croaked like they were sharing secrets, and birds that sang unfamiliar melodies. Despite the eerie feeling curling around his paws, Whiskers pressed on.\\n\\nAfter what felt like hours, he arrived at a clearing with a peculiar sight: a large cage in the center with a small bird trapped inside. The bird chirped desperately, its tiny eyes pleading for help. Whiskers, though naturally inclined to chase birds, felt a tug of compassion watching the helpless creature.\\n\\nUsing his sharp claws, Whiskers carefully picked at the lock until it clicked open. The bird flapped its wings gratefully and soared into the sky, singing a joyful tune. Whiskers watched it disappear among the clouds, a warm feeling blossoming in his chest.\\n\\nContent with his good deed, Whiskers made his way back home, sticking to the original path. As he lay in his favorite sun-dappled spot on the porch, he reflected on his adventure.\\n\\nThe moral of the story is: Curiosity is a beautiful thing that leads to new discoveries, but it must be guided by kindness and the courage to act, for it is in helping others that we find our true purpose.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=395, prompt_tokens=528, total_tokens=923, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'story_with_moral', 'args': (), 'kwargs': {'topic': 'a curious cat'}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': \"Write a story about a curious cat in the style: moral.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{\"topic\":\"a curious cat\"}', 'name': 'story_with_moral'}, 'id': 'call_nJMDv3AxDTvyxxoDKXAzH4aB', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_nJMDv3AxDTvyxxoDKXAzH4aB', 'name': 'story_with_moral', 'content': [{'type': 'text', 'text': 'In a quaint village nestled between rolling hills and whispering streams, there lived a cat named Whiskers. Whiskers was not an ordinary cat; his sleek, shiny coat gleamed under the sun, and his eyes sparkled with a clever curiosity that set him apart. His inquisitive nature drove him to explore every nook and cranny of the village, always seeking new adventures.\\n\\nOne day, while wandering near the woods, Whiskers stumbled upon a mysterious path he had never seen before. The path was lined with wildflowers and arched by towering trees that seemed to stretch on forever. Intrigued, Whiskers decided to follow it to see where it would lead.\\n\\nThe further he ventured, the stranger the path became. He encountered bubbling brooks, frogs that croaked like they were sharing secrets, and birds that sang unfamiliar melodies. Despite the eerie feeling curling around his paws, Whiskers pressed on.\\n\\nAfter what felt like hours, he arrived at a clearing with a peculiar sight: a large cage in the center with a small bird trapped inside. The bird chirped desperately, its tiny eyes pleading for help. Whiskers, though naturally inclined to chase birds, felt a tug of compassion watching the helpless creature.\\n\\nUsing his sharp claws, Whiskers carefully picked at the lock until it clicked open. The bird flapped its wings gratefully and soared into the sky, singing a joyful tune. Whiskers watched it disappear among the clouds, a warm feeling blossoming in his chest.\\n\\nContent with his good deed, Whiskers made his way back home, sticking to the original path. As he lay in his favorite sun-dappled spot on the porch, he reflected on his adventure.\\n\\nThe moral of the story is: Curiosity is a beautiful thing that leads to new discoveries, but it must be guided by kindness and the courage to act, for it is in helping others that we find our true purpose.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOQIJsyohvBlsBGz9cztpetifUP', created=1765834058, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's a story about a curious cat named Whiskers who embarks on an adventure that teaches him an important lesson about kindness and courage. Whiskers' curiosity leads him to explore a mysterious path where he eventually discovers a trapped bird. Instead of succumbing to his natural instincts, Whiskers chooses to help the bird, freeing it from its cage. Through this act of compassion, Whiskers learns that while curiosity can lead to new discoveries, it is the courage to act with kindness that truly defines us.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=105, prompt_tokens=982, total_tokens=1087, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "Here's a story about a curious cat named Whiskers who embarks on an adventure that teaches him an important lesson about kindness and courage. Whiskers' curiosity leads him to explore a mysterious path where he eventually discovers a trapped bird. Instead of succumbing to his natural instincts, Whiskers chooses to help the bird, freeing it from its cage. Through this act of compassion, Whiskers learns that while curiosity can lead to new discoveries, it is the courage to act with kindness that truly defines us.\n",
      "\n",
      "=== Funny story ===\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': \"Write a story about a curious cat in the style: funny.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOTXQYpAjE6AhrSHrREbvtgiSzs', created=1765834061, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{\"topic\":\"a curious cat\"}', name='story_funny'), id='call_zMjPfWzaDFKuswF7HiHFFu4R', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=17, prompt_tokens=560, total_tokens=577, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Write a funny, humorous story about a curious cat. Do not use any tools.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOUficJNRttQKM2b9t8qJDzfXnQ', created=1765834062, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Once upon a time in the quaint little town of Whiskerfield, there lived a particularly curious cat named Whiskers. Now, Whiskers wasn't your average feline; he had a knack for getting himself into the most bizarre situations, much to the amusement of the townsfolk.\\n\\nOne sunny morning, as Whiskers ventured out of his cozy basket, he noticed a peculiar shiny object gleaming in the garden. It was unlike anything he had ever seen before  a mix between a large spoon and a tiny satellite dish. His curiosity piqued, Whiskers approached with his usual stealth, attempting to decipher this mysterious contraption.\\n\\nUnbeknownst to Whiskers, the shiny object was none other than the town's new state-of-the-art bird feeder, designed with reflective surfaces to keep the squirrels away. But to Whiskers, it was the most intriguing puzzle he'd ever encountered. With his tail twitching like a metronome, Whiskers pounced at the feeder, only to collide with its slippery surface and land unceremoniously on his back, paws in the air.\\n\\nUndeterred by his clumsy introduction, Whiskers began his investigation with fervor. He circled the feeder, pawing at it and meowing loudly, as if expecting a response. The neighborhood birds watched from a safe distance, chirping in a chorus that resembled laughter. Whiskers, paying no mind to his feathered audience, was determined to unlock the secrets of this shiny beacon.\\n\\nAs noon approached, Whiskers, now slightly exasperated and hungry, decided to enlist the help of his best friend, Rover the golden retriever. Rover, although quite good-natured, wasn't exactly the brains of their operation, but he was always up for an adventure. With wagging tails and determined purrs, the duo devised a plan. Rover would use his weight to tip the feeder, while Whiskers would keep an eye out for any unexpected critters.\\n\\nThe plan was in motion. Rover, in his typical bounding style, lunged at the feeder, causing it to wobble precariously. Just as it began to tip, a sudden gust of wind swung the contraption in a whirlwind of seeds and reflections. Whiskers and Rover, caught in the midst of this flying feast, found themselves covered in birdseed, with Whiskers' fur boasting a collection of tiny sunflower hats.\\n\\nAs they sat there, bewildered and giggling in their own peculiar way, the townsfolk couldn't help but chuckle at the antics of Whiskers and Rover. Even the birds stopped their fluttering to admire the spectacle. From that day on, the bird feeder was not just a source of food for the birds, but also a stage for Whiskerfield's most unexpected entertainment duo.\\n\\nAnd so, Whiskers the curious cat learned an important lesson: sometimes, curiosity might not uncover the mysteries you expect, but it certainly creates the most memorable adventures. And as for Rover, well, he just loved being part of the fun, birdseed hats and all.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=632, prompt_tokens=524, total_tokens=1156, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'story_funny', 'args': (), 'kwargs': {'topic': 'a curious cat'}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': \"Write a story about a curious cat in the style: funny.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{\"topic\":\"a curious cat\"}', 'name': 'story_funny'}, 'id': 'call_zMjPfWzaDFKuswF7HiHFFu4R', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_zMjPfWzaDFKuswF7HiHFFu4R', 'name': 'story_funny', 'content': [{'type': 'text', 'text': \"Once upon a time in the quaint little town of Whiskerfield, there lived a particularly curious cat named Whiskers. Now, Whiskers wasn't your average feline; he had a knack for getting himself into the most bizarre situations, much to the amusement of the townsfolk.\\n\\nOne sunny morning, as Whiskers ventured out of his cozy basket, he noticed a peculiar shiny object gleaming in the garden. It was unlike anything he had ever seen before  a mix between a large spoon and a tiny satellite dish. His curiosity piqued, Whiskers approached with his usual stealth, attempting to decipher this mysterious contraption.\\n\\nUnbeknownst to Whiskers, the shiny object was none other than the town's new state-of-the-art bird feeder, designed with reflective surfaces to keep the squirrels away. But to Whiskers, it was the most intriguing puzzle he'd ever encountered. With his tail twitching like a metronome, Whiskers pounced at the feeder, only to collide with its slippery surface and land unceremoniously on his back, paws in the air.\\n\\nUndeterred by his clumsy introduction, Whiskers began his investigation with fervor. He circled the feeder, pawing at it and meowing loudly, as if expecting a response. The neighborhood birds watched from a safe distance, chirping in a chorus that resembled laughter. Whiskers, paying no mind to his feathered audience, was determined to unlock the secrets of this shiny beacon.\\n\\nAs noon approached, Whiskers, now slightly exasperated and hungry, decided to enlist the help of his best friend, Rover the golden retriever. Rover, although quite good-natured, wasn't exactly the brains of their operation, but he was always up for an adventure. With wagging tails and determined purrs, the duo devised a plan. Rover would use his weight to tip the feeder, while Whiskers would keep an eye out for any unexpected critters.\\n\\nThe plan was in motion. Rover, in his typical bounding style, lunged at the feeder, causing it to wobble precariously. Just as it began to tip, a sudden gust of wind swung the contraption in a whirlwind of seeds and reflections. Whiskers and Rover, caught in the midst of this flying feast, found themselves covered in birdseed, with Whiskers' fur boasting a collection of tiny sunflower hats.\\n\\nAs they sat there, bewildered and giggling in their own peculiar way, the townsfolk couldn't help but chuckle at the antics of Whiskers and Rover. Even the birds stopped their fluttering to admire the spectacle. From that day on, the bird feeder was not just a source of food for the birds, but also a stage for Whiskerfield's most unexpected entertainment duo.\\n\\nAnd so, Whiskers the curious cat learned an important lesson: sometimes, curiosity might not uncover the mysteries you expect, but it certainly creates the most memorable adventures. And as for Rover, well, he just loved being part of the fun, birdseed hats and all.\"}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOfnzkwylzEgoQjoqCoqso1JcbO', created=1765834073, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Here's a funny story about a curious cat named Whiskers. In the quaint town of Whiskerfield, Whiskers is known for getting into bizarre situations. One day, he discovers a shiny bird feeder and mistakes it for a mysterious contraption. Despite several comedic mishaps, including enlisting the help of Rover the golden retriever, Whiskers ends up covered in birdseed, providing entertainment for the entire town. Through his antics, Whiskers realizes that while curiosity might not solve mysteries, it sure makes for adventurous tales.\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=111, prompt_tokens=1217, total_tokens=1328, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "Here's a funny story about a curious cat named Whiskers. In the quaint town of Whiskerfield, Whiskers is known for getting into bizarre situations. One day, he discovers a shiny bird feeder and mistakes it for a mysterious contraption. Despite several comedic mishaps, including enlisting the help of Rover the golden retriever, Whiskers ends up covered in birdseed, providing entertainment for the entire town. Through his antics, Whiskers realizes that while curiosity might not solve mysteries, it sure makes for adventurous tales.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools\n",
    "assert story_funny in write_story.tools\n",
    "print(\"Sub-templates available to write_story:\", list(write_story.tools))\n",
    "\n",
    "with handler(provider), handler(llm_logger):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": [
    "### Retrying LLM Requests\n",
    "LLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls:\n",
    "\n",
    "- `max_retries`: Maximum number of retry attempts (default: 3)\n",
    "- `add_error_feedback`: When `True`, appends the error message to the prompt on retry, helping the LLM correct its output.\n",
    "- `exception_cls`: RetryHandler will only attempt to try again when a specific type of `Exception` is thrown.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOpUS8BAytmElgOX8fLDSSym8TP', created=1765834083, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_T6RgNagFWflpLfddbDdAhy7e', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOqUGCwcplfEVlflhfHFeoN0vmV', created=1765834084, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_1zL43TYBfRd82z76Ww3VtZ10', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOrjGy3cKfupoXxoUpyh5g3Rg2i', created=1765834085, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_QIhDdQlUVyQb4xL3bp9mA3Ln', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOrSd4OYuyZMTYJQEH8nAuKmbII', created=1765834085, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_ndnD0MTgx5kCh0RQloWTEMDO', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOs7Deh2JdFir6jSkT2tvgXUwAD', created=1765834086, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_zZZ2qOKtJOSK0NQR05Es8GCT', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOsEkupw6S2qV7dAVO6IXlv48fE', created=1765834086, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_SROFh6GD7MXpKjEjuCKfwsoR', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOtOfJnpaXYL7B3vdnHZKo7CfTQ', created=1765834087, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_OfaqegdBaNqhYXbmtMSfq8E3', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOu2KvgpurkvKS5js70BrYPZ6ei', created=1765834088, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='fetch_data'), id='call_G1XWytSwDBOJXd5DbTnAgegd', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=10, prompt_tokens=553, total_tokens=563, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOuyGE1IdeXQAUdAihmAEuou0Nm', created=1765834088, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_e819e3438b', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='unstable_service'), id='call_yefiR7zjd3zhSaL4hO2IlVPz', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=11, prompt_tokens=553, total_tokens=564, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'name': 'unstable_service', 'content': \"{'status': 'failure', 'exception': 'Service unavailable! Attempt 1/3. Please retry.'}\"}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOv3DETvRpajf5oFobKAex8uI4c', created=1765834089, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='unstable_service'), id='call_WKh4jx4XtF95mgUTv8uAXlLE', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=11, prompt_tokens=596, total_tokens=607, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'name': 'unstable_service', 'content': \"{'status': 'failure', 'exception': 'Service unavailable! Attempt 1/3. Please retry.'}\"}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_WKh4jx4XtF95mgUTv8uAXlLE', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_WKh4jx4XtF95mgUTv8uAXlLE', 'name': 'unstable_service', 'content': \"{'status': 'failure', 'exception': 'Service unavailable! Attempt 2/3. Please retry.'}\"}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOwAICzWpytXVphXANfC6ix6Iv6', created=1765834090, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='tool_calls', index=0, message=Message(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(function=Function(arguments='{}', name='unstable_service'), id='call_g20DJy4DQvADfZGwqnNClZf7', type='function')], function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=11, prompt_tokens=639, total_tokens=650, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'unstable_service', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_yefiR7zjd3zhSaL4hO2IlVPz', 'name': 'unstable_service', 'content': \"{'status': 'failure', 'exception': 'Service unavailable! Attempt 1/3. Please retry.'}\"}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_WKh4jx4XtF95mgUTv8uAXlLE', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_WKh4jx4XtF95mgUTv8uAXlLE', 'name': 'unstable_service', 'content': \"{'status': 'failure', 'exception': 'Service unavailable! Attempt 2/3. Please retry.'}\"}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'unstable_service'}, 'id': 'call_g20DJy4DQvADfZGwqnNClZf7', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_g20DJy4DQvADfZGwqnNClZf7', 'name': 'unstable_service', 'content': [{'type': 'text', 'text': \"{ 'status': 'ok', 'data': [1, 2, 3] }\"}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOwp4xrlzgidgfQPxc56WoCermB', created=1765834090, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='The data fetched from the unstable service is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=20, prompt_tokens=679, total_tokens=699, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_G1XWytSwDBOJXd5DbTnAgegd', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_G1XWytSwDBOJXd5DbTnAgegd', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'The data fetched from the unstable service is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOxj5IZQ85aFjs4jCuNolWoY9OL', created=1765834091, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='The data fetched from the unstable service is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=20, prompt_tokens=590, total_tokens=610, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_OfaqegdBaNqhYXbmtMSfq8E3', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_OfaqegdBaNqhYXbmtMSfq8E3', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'The data fetched from the unstable service is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOx62IhQMgrL2JUgPzFMn7RImks', created=1765834091, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully fetched the data from the unstable service: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=21, prompt_tokens=590, total_tokens=611, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_SROFh6GD7MXpKjEjuCKfwsoR', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_SROFh6GD7MXpKjEjuCKfwsoR', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully fetched the data from the unstable service: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAOyXctxr4R0RMfvWHsU5AYqAIOY', created=1765834092, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=26, prompt_tokens=591, total_tokens=617, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_zZZ2qOKtJOSK0NQR05Es8GCT', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_zZZ2qOKtJOSK0NQR05Es8GCT', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAP0wwqVQC9MyAl9zWVe7zzCHxAC', created=1765834094, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=26, prompt_tokens=596, total_tokens=622, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_ndnD0MTgx5kCh0RQloWTEMDO', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_ndnD0MTgx5kCh0RQloWTEMDO', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAP0MVlZ9RfdBubfjSXaW6MoAdrL', created=1765834094, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=26, prompt_tokens=596, total_tokens=622, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_QIhDdQlUVyQb4xL3bp9mA3Ln', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_QIhDdQlUVyQb4xL3bp9mA3Ln', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAP1erUfmc0ilFRVBJTR0bcGcrmx', created=1765834095, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=26, prompt_tokens=596, total_tokens=622, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_1zL43TYBfRd82z76Ww3VtZ10', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_1zL43TYBfRd82z76Ww3VtZ10', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully fetched the data from the unstable service, and the data is: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAP2E2oVkYct8MOs2A5fRhpclikB', created=1765834096, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully retrieved the data from the unstable service: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=21, prompt_tokens=596, total_tokens=617, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'tool': 'fetch_data', 'args': (), 'kwargs': {}}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Use the unstable_service tool to fetch data.'}], 'role': 'user'}, {'content': None, 'role': 'assistant', 'tool_calls': [{'function': {'arguments': '{}', 'name': 'fetch_data'}, 'id': 'call_T6RgNagFWflpLfddbDdAhy7e', 'type': 'function'}], 'function_call': None, 'provider_specific_fields': {'refusal': None}, 'annotations': []}, {'role': 'tool', 'tool_call_id': 'call_T6RgNagFWflpLfddbDdAhy7e', 'name': 'fetch_data', 'content': [{'type': 'text', 'text': 'I successfully retrieved the data from the unstable service: `[1, 2, 3]`.'}]}], 'response_format': None, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAP233bZtdUk1k1OCTmZHwHE9jN2', created=1765834096, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='I successfully retrieved the data from the unstable service: `[1, 2, 3]`.', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=21, prompt_tokens=591, total_tokens=612, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "Result: I successfully retrieved the data from the unstable service: `[1, 2, 3]`. Retries: 3\n"
     ]
    }
   ],
   "source": [
    "call_count = 0\n",
    "REQUIRED_RETRIES = 3\n",
    "\n",
    "\n",
    "@defop\n",
    "def unstable_service() -> str:\n",
    "    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if call_count < REQUIRED_RETRIES:\n",
    "        raise ConnectionError(\n",
    "            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n",
    "        )\n",
    "    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n",
    "\n",
    "\n",
    "@Template.define  # unstable_service auto-captured from lexical scope\n",
    "def fetch_data() -> str:\n",
    "    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "retry_handler = RetryLLMHandler(max_retries=5, add_error_feedback=True)\n",
    "\n",
    "with handler(provider), handler(retry_handler), handler(llm_logger):\n",
    "    result = fetch_data()\n",
    "    print(f\"Result: {result}\", \"Retries:\", call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "### Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Give a rating for Die Hard. The explanation MUST include the numeric score. Do not use any tools.'}], 'role': 'user'}], 'response_format': <class 'effectful.handlers.llm.providers.Response'>, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'give_rating_for_movie', 'description': 'Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'movie_name': {'title': 'Movie Name', 'type': 'string'}}, 'required': ['movie_name'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAPBMGNLhpSkzfqzv3kQfvYaTcmO', created=1765834105, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\"value\":{\"score\":9,\"explanation\":\"Die Hard is a classic action film that set a high standard for the genre, known for its thrilling action sequences and memorable performances, particularly by Bruce Willis as John McClane. The film\\'s strong plot, engaging characters, and suspenseful pacing contribute to its enduring popularity. Given its influential status and entertainment value, Die Hard deserves a high rating of 9 out of 10.\"}}', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=92, prompt_tokens=681, total_tokens=773, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "INFO {'args': (), 'kwargs': {'messages': [{'type': 'message', 'content': [{'type': 'text', 'text': 'Retry generating the following prompt: Give a rating for Die Hard. The explanation MUST include the numeric score. Do not use any tools.\\n\\nError from previous generation:\\n```\\nTraceback (most recent call last):\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/handlers/llm/providers.py\", line 347, in _retry_completion\\n    return fwd(current_template, *args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/ops/types.py\", line 485, in __call__\\n    return self_handler(*args, **kwargs)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 81, in inner\\n    return func(*args, **kwds)\\n           ^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/internals/runtime.py\", line 45, in _cont_wrapper\\n    return fn(*a, **k)\\n           ^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/internals/runtime.py\", line 56, in _cont_wrapper\\n    return fn(*a, **k)\\n           ^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/internals/runtime.py\", line 70, in bound_body\\n    return body(*a, **k)\\n           ^^^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/internals/runtime.py\", line 56, in _cont_wrapper\\n    return fn(*a, **k)\\n           ^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/handlers/llm/providers.py\", line 492, in _call\\n    return decode_response(template, resp)\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/effectful/handlers/llm/providers.py\", line 436, in decode_response\\n    result = Result.model_validate_json(result_str)\\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\n  File \"/Users/datnguyenthanh/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py\", line 766, in model_validate_json\\n    return cls.__pydantic_validator__.validate_json(\\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\\npydantic_core._pydantic_core.ValidationError: 1 validation error for Result\\nvalue.score\\n  score must be 15, got 9 [type=invalid_score, input_value=9, input_type=int]\\n```'}], 'role': 'user'}], 'response_format': <class 'effectful.handlers.llm.providers.Response'>, 'tools': [{'type': 'function', 'function': {'name': 'limerick', 'description': 'Write a limerick on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'haiku_no_cache', 'description': 'Write a haiku on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'primes', 'description': 'Give a prime number with {first_digit} as the first digit. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'first_digit': {'title': 'First Digit', 'type': 'integer'}}, 'required': ['first_digit'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'count_char', 'description': \"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\", 'parameters': {'additionalProperties': False, 'properties': {'char': {'title': 'Char', 'type': 'string'}}, 'required': ['char'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'cities', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'weather', 'description': '', 'parameters': {'additionalProperties': False, 'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'vacation', 'description': 'Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_joke', 'description': 'Write a knock-knock joke on the theme of {theme}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'theme': {'title': 'Theme', 'type': 'string'}}, 'required': ['theme'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'rate_joke', 'description': 'Decide if {joke} is funny or not. Do not use any tools.', 'parameters': {'$defs': {'KnockKnockJoke': {'properties': {'whos_there': {'title': 'Whos There', 'type': 'string'}, 'punchline': {'title': 'Punchline', 'type': 'string'}}, 'required': ['whos_there', 'punchline'], 'title': 'KnockKnockJoke', 'type': 'object', 'additionalProperties': False}}, 'additionalProperties': False, 'properties': {'joke': {'$ref': '#/$defs/KnockKnockJoke'}}, 'required': ['joke'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_with_moral', 'description': 'Write a short story about {topic} and end with a moral lesson. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'story_funny', 'description': 'Write a funny, humorous story about {topic}. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}}, 'required': ['topic'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'write_story', 'description': \"Write a story about {topic} in the style: {style}.\\n    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\", 'parameters': {'additionalProperties': False, 'properties': {'topic': {'title': 'Topic', 'type': 'string'}, 'style': {'title': 'Style', 'type': 'string'}}, 'required': ['topic', 'style'], 'title': 'Params', 'type': 'object'}, 'strict': True}}, {'type': 'function', 'function': {'name': 'unstable_service', 'description': 'Fetch data from an unstable external service. May require retries.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'fetch_data', 'description': 'Use the unstable_service tool to fetch data.', 'parameters': {'additionalProperties': False, 'properties': {}, 'title': 'Params', 'type': 'object', 'required': []}, 'strict': True}}, {'type': 'function', 'function': {'name': 'give_rating_for_movie', 'description': 'Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.', 'parameters': {'additionalProperties': False, 'properties': {'movie_name': {'title': 'Movie Name', 'type': 'string'}}, 'required': ['movie_name'], 'title': 'Params', 'type': 'object'}, 'strict': True}}]}, 'response': ModelResponse(id='chatcmpl-CnAPDokOZODkN8VxElAwlcaUZdLuL', created=1765834107, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_83554c687e', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\"value\":{\"score\":5,\"explanation\":\"Die Hard is an iconic action film that has become a staple of the genre. With its engaging plot, intense action sequences, and a memorable performance by Bruce Willis, it easily earns a score of 5 out of 5. The film\\'s blend of suspense and humor sets it apart, making it a must-watch for action movie enthusiasts.\"}}', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=83, prompt_tokens=1268, total_tokens=1351, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None, image_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier='default')}\n",
      "Score: 5/5\n",
      "Explanation: Die Hard is an iconic action film that has become a staple of the genre. With its engaging plot, intense action sequences, and a memorable performance by Bruce Willis, it easily earns a score of 5 out of 5. The film's blend of suspense and humor sets it apart, making it a must-watch for action movie enthusiasts.\n"
     ]
    }
   ],
   "source": [
    "import pydantic\n",
    "from pydantic import ValidationError, field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "\n",
    "@pydantic.dataclasses.dataclass\n",
    "class Rating:\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "    @field_validator(\"score\")\n",
    "    @classmethod\n",
    "    def check_score(cls, v):\n",
    "        if v < 1 or v > 5:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_score\",\n",
    "                \"score must be 15, got {v}\",\n",
    "                {\"v\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"explanation\")\n",
    "    @classmethod\n",
    "    def check_explanation_contains_score(cls, v, info):\n",
    "        score = info.data.get(\"score\", None)\n",
    "        if score is not None and str(score) not in v:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_explanation\",\n",
    "                \"explanation must mention the score {score}, got '{explanation}'\",\n",
    "                {\"score\": score, \"explanation\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def give_rating_for_movie(movie_name: str) -> Rating:\n",
    "    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# RetryLLMHandler with error feedback - the traceback helps LLM correct validation errors\n",
    "# Note: Pydantic wraps PydanticCustomError inside ValidationError, so we catch ValidationError instead\n",
    "retry_handler = RetryLLMHandler(\n",
    "    max_retries=3,\n",
    "    add_error_feedback=True,\n",
    "    exception_cls=ValidationError,  # Catch validation errors\n",
    ")\n",
    "\n",
    "with handler(provider), handler(retry_handler), handler(llm_logger):\n",
    "    rating = give_rating_for_movie(\"Die Hard\")\n",
    "    print(f\"Score: {rating.score}/5\")\n",
    "    print(f\"Explanation: {rating.explanation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
