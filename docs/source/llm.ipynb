{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fda1b8",
   "metadata": {},
   "source": [
    "# LLM Interface\n",
    "The `effectful.handlers.llm` module provides a simplified LLM interface that uses algebraic effects for modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `Template.define` which creates a prompt template from a callable. A template is an LLM-implemented function whose behavior is specified by a template string. When a template is called, an LLM is invoked to produce the specified behavior.\n",
    "- A decorator `Tool.define` which exposes Python callables as tools that templates can call. Tool signatures and docstrings define the schema passed to the model.\n",
    "- Structured output handling via `Encodable` (used internally by templates and tool calls) to serialize/deserialize Python types.\n",
    "- LLM providers such as `LiteLLMProvider`, and reliability helpers like `RetryLLMHandler` and `ReplayLiteLLMProvider`, which can be composed with `handler(...)` to control execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import dataclasses\n",
    "import functools\n",
    "import inspect\n",
    "import io\n",
    "from collections.abc import Callable\n",
    "from typing import Literal\n",
    "\n",
    "import litellm\n",
    "import pydantic\n",
    "from IPython.display import HTML, display\n",
    "from litellm.caching.caching import Cache\n",
    "from PIL import Image\n",
    "from pydantic import field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "from effectful.handlers.llm import Template, Tool\n",
    "from effectful.handlers.llm.completions import (\n",
    "    LiteLLMProvider,\n",
    "    RetryLLMHandler,\n",
    ")\n",
    "from effectful.handlers.llm.doctest import DoctestHandler\n",
    "from effectful.handlers.llm.evaluation import UnsafeEvalProvider\n",
    "from effectful.ops.semantics import NotHandled, handler\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093243e0",
   "metadata": {},
   "source": [
    "In the following sections, we walk through each of the mentioned components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a pond where the waters are still,\n",
      "Lived a fish with a notable skill,\n",
      "He'd leap in the air,\n",
      "With grace that was rare,\n",
      "And land with a splash for a thrill!\n",
      "----------------------------------------\n",
      "In the sea where the big fishes play,\n",
      "A small fish swam every which way.\n",
      "With eyes wide and bright,\n",
      "It jumped with delight,\n",
      "Dodging hooks while it danced in the bay.\n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or use LiteLLM's built-in cache by setting a cache backend and passing `caching=True` to the provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In still waters, grace,\n",
      "Silver scales in sunlit dance,\n",
      "Fish swim, life unfolds.\n",
      "----------------------------------------\n",
      "In still waters, grace,\n",
      "Silver scales in sunlit dance,\n",
      "Fish swim, life unfolds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendat/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='{\"value\"...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimming in the deep,  \n",
      "Silent fins glide through the waves,  \n",
      "Secrets in the blue.\n",
      "----------------------------------------\n",
      "Silent waters gleam,  \n",
      "Fish weave tales beneath the waves,  \n",
      "Nature's fluid dance.\n",
      "\n",
      "Below ripples glide,\n",
      "Silver scales in liquid dance,\n",
      "Nature's grace in flow.\n",
      "----------------------------------------\n",
      "Silent waters flow,  \n",
      "Where vibrant scales shimmer bright,  \n",
      "Fish dance in moon's glow.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "# Enable LiteLLM caching by setting a cache backend and enabling caching.\n",
    "litellm.cache = Cache()\n",
    "provider_cached = LiteLLMProvider(caching=True)\n",
    "try:\n",
    "    with handler(provider_cached):\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "        print(\"-\" * 40)\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "finally:\n",
    "    litellm.cache = None\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. Callable synthesis is supported via `Encodable` and the evaluation providers in `effectful.handlers.llm.evaluation` (`UnsafeEvalProvider` or `RestrictedEvalProvider`), which enable parsing/compiling/executing synthesized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_char(s: str) -> int:\n",
      "    return s.count('a')\n"
     ]
    }
   ],
   "source": [
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function named count_char which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Use UnsafeEvalProvider for simple examples; RestrictedEvalProvider may need extra globals.\n",
    "# DoctestHandler is not required for synthesis -- it is optional.\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a7b48",
   "metadata": {},
   "source": [
    "### Doctest Semantic Constraints\n",
    "\n",
    "The `DoctestHandler` uses `>>>` examples in template docstrings as **semantic constraints** rather than literal prompts. It handles two cases automatically based on the template's return type:\n",
    "\n",
    "- **Case 1 (tool-calling)**: When the template returns a non-`Callable` type (e.g. `str`, `int`), the handler runs a *calibration loop* once per template definition — calling the LLM with the doctest inputs, checking outputs, and caching the full conversation (including any corrections) as a few-shot prefix for future calls.\n",
    "- **Case 2 (code generation)**: When the template returns a `Callable` type, the generated code must pass the doctests. A `ResultDecodingError` is raised on failure.\n",
    "\n",
    "Notes: *In both cases, `>>>` examples are **stripped from the prompt** so the LLM cannot simply memorise the expected outputs.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a2603",
   "metadata": {},
   "source": [
    "#### Case 1: Tool-Calling Calibration\n",
    "\n",
    "For templates that return a non-`Callable` type (e.g. `str`), `DoctestHandler` runs a calibration loop the first time the template is called. It invokes the LLM with each doctest input, checks whether the output matches, and appends corrective feedback if not. The entire conversation — successes *and* failures — is cached as a few-shot prefix that teaches the LLM the template's expected behaviour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6524592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without DoctestHandler: Python is recognized for its readability as a high-level programming language.\n",
      "With DoctestHandler:    Python is a readable, high-level programming language.\n",
      "\n",
      "Calibration prefix cached: True\n",
      "Prefix messages: 4\n"
     ]
    }
   ],
   "source": [
    "@Template.define\n",
    "def summarize_doctest(text: str) -> str:\n",
    "    \"\"\"Summarize the following text into a single concise sentence: '{text}'\n",
    "\n",
    "    >>> summarize_doctest(\"The quick brown fox jumps over the lazy dog near the river bank on a sunny afternoon.\")\n",
    "    'A fox jumps over a lazy dog by a river on a sunny day.'\n",
    "    >>> summarize_doctest(\"What a beautiful day!\")\n",
    "    'A beautiful day!'\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Without DoctestHandler: the template works, but the LLM has no calibration prefix.\n",
    "with handler(provider):\n",
    "    result_no_doctest = summarize_doctest(\n",
    "        \"Python is a high-level programming language known for its readability.\"\n",
    "    )\n",
    "    print(f\"Without DoctestHandler: {result_no_doctest}\")\n",
    "\n",
    "# With DoctestHandler: calibration runs once, building a few-shot prefix.\n",
    "# Subsequent calls benefit from the prefix.\n",
    "doctest_handler = DoctestHandler()\n",
    "with handler(provider), handler(doctest_handler):\n",
    "    result_with_doctest = summarize_doctest(\n",
    "        \"Python is a high-level programming language known for its readability.\"\n",
    "    )\n",
    "    print(f\"With DoctestHandler:    {result_with_doctest}\")\n",
    "\n",
    "# The calibration prefix is cached for the template.\n",
    "print(\n",
    "    f\"\\nCalibration prefix cached: {summarize_doctest in doctest_handler._prefix_cache}\"\n",
    ")\n",
    "print(\n",
    "    f\"Prefix messages: {len(doctest_handler._prefix_cache.get(summarize_doctest, []))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8981316",
   "metadata": {},
   "source": [
    "#### Case 2: Code Generation Validation\n",
    "\n",
    "When synthesising callable code, `DoctestHandler` validates that the generated function passes the doctests.\n",
    "Without it, synthesis succeeds even if the docstring examples don't match the generated code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "793b12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without DoctestHandler: synthesis succeeded (doctest not checked)\n",
      "  count_a('banana') = 3\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   1 in __main__.__template_doctest__\n",
      "***Test Failed*** 1 failures.\n",
      "With DoctestHandler: synthesis failed as expected\n",
      "  Error: ResultDecodingError\n"
     ]
    }
   ],
   "source": [
    "from effectful.handlers.llm.completions import ResultDecodingError\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def count_char_with_bad_doctest(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function named count_char that counts the occurrances of '{char}'.\n",
    "    Do not use any tools.\n",
    "\n",
    "        >>> count_char(\"banana\")\n",
    "        999\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Without DoctestHandler: synthesis succeeds (doctest is NOT checked)\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char_with_bad_doctest(\"a\")\n",
    "    assert callable(count_a)\n",
    "    print(\"Without DoctestHandler: synthesis succeeded (doctest not checked)\")\n",
    "    print(f\"  count_a('banana') = {count_a('banana')}\")\n",
    "\n",
    "# With DoctestHandler: synthesis fails because the doctest expects 999 but gets 3\n",
    "try:\n",
    "    with handler(provider), handler(UnsafeEvalProvider()), handler(DoctestHandler()):\n",
    "        count_a = count_char_with_bad_doctest(\"a\")\n",
    "except ResultDecodingError as e:\n",
    "    print(\"With DoctestHandler: synthesis failed as expected\")\n",
    "    print(f\"  Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among the cities listed, Barcelona currently has good weather, being described as \"sunny.\"\n"
     ]
    }
   ],
   "source": [
    "@Tool.define\n",
    "def cities() -> list[str]:\n",
    "    \"\"\"Return a list of cities that can be passed to `weather`.\"\"\"\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Given a city name, return a description of the weather in that city.\"\"\"\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59584a54",
   "metadata": {},
   "source": [
    "## Image Inputs\n",
    "\n",
    "You can pass `PIL.Image.Image` values directly to templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89992702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqAMAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQAmgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\" alt=\"Example image\" width=\"320\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple yellow smiley face with black eyes and a smile.\n"
     ]
    }
   ],
   "source": [
    "image_base64 = (\n",
    "    \"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqA\"\n",
    "    \"MAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg\"\n",
    "    \"+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQA\"\n",
    "    \"mgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\"\n",
    ")\n",
    "image = Image.open(io.BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def describe_image(image: Image.Image) -> str:\n",
    "    \"\"\"Return a short description of the following image.\n",
    "    {image}\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Example image\" width=\"320\" />'\n",
    "        )\n",
    "    )\n",
    "    print(describe_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Lizard.\n",
      "Lizard who?\n",
      "Lizard who? Lizard you can't hear, but I'm still knocking!\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'summarize_doctest', 'count_char_with_bad_doctest', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny'])\n",
      "=== Story with moral ===\n",
      "\n",
      "\n",
      "Whiskers learned this valuable lesson and became a wiser cat, embarking on adventures that were both thrilling and safe, living happily amidst his curious wonders.\n",
      "\n",
      "=== Funny story ===\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Pickles' story teaches us that sometimes, embracing our curiosity can lead to the unexpected, and perhaps hilariously so! But, in embracing what makes us different, we might just bring joy to those around us, too.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools.values()\n",
    "assert story_funny in write_story.tools.values()\n",
    "print(\"Sub-templates available to write_story:\", write_story.tools.keys())\n",
    "\n",
    "with handler(provider):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": [
    "## Retrying LLM Requests\n",
    "LLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls and can also surface tool/runtime errors as tool messages:\n",
    "\n",
    "- `num_retries`: Maximum number of retry attempts (default: 3)\n",
    "- `include_traceback`: When `True`, include traceback details in the error feedback (default: False)\n",
    "- `catch_tool_errors`: Exception type(s) to catch during tool execution (default: `Exception`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Service unavailable! Attempt 1/3. Please retry.\n",
      "Result: The data fetched successfully is: `[1, 2, 3]`. \n",
      "\n",
      "If you need further assistance with this data or have any other queries, feel free to ask! Retries: 3\n"
     ]
    }
   ],
   "source": [
    "call_count = 0\n",
    "REQUIRED_RETRIES = 3\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def unstable_service() -> str:\n",
    "    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if call_count < REQUIRED_RETRIES:\n",
    "        raise ConnectionError(\n",
    "            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n",
    "        )\n",
    "    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n",
    "\n",
    "\n",
    "@Template.define  # unstable_service auto-captured from lexical scope\n",
    "def fetch_data() -> str:\n",
    "    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        result = fetch_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler(num_retries=3)):\n",
    "    result = fetch_data()\n",
    "    print(f\"Result: {result}\", \"Retries:\", call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "## Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error decoding response: 1 validation error for Response\n",
      "value.score\n",
      "  score must be 1–5, got 9 [type=invalid_score, input_value=9, input_type=int]. Please provide a valid response and try again.\n",
      "Score: 5/5\n",
      "Explanation: Die Hard is a classic action film that's widely regarded as one of the best in its genre. It features intense action sequences, memorable one-liners, and a charismatic performance by Bruce Willis. The film's clever plot and well-executed direction keep viewers on the edge of their seats. Given its enduring popularity and influence on the action genre, I would rate it a 5 out of 5.\n"
     ]
    }
   ],
   "source": [
    "@pydantic.dataclasses.dataclass\n",
    "class Rating:\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "    @field_validator(\"score\")\n",
    "    @classmethod\n",
    "    def check_score(cls, v):\n",
    "        if v < 1 or v > 5:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_score\",\n",
    "                \"score must be 1–5, got {v}\",\n",
    "                {\"v\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"explanation\")\n",
    "    @classmethod\n",
    "    def check_explanation_contains_score(cls, v, info):\n",
    "        score = info.data.get(\"score\", None)\n",
    "        if score is not None and str(score) not in v:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_explanation\",\n",
    "                \"explanation must mention the score {score}, got '{explanation}'\",\n",
    "                {\"score\": score, \"explanation\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def give_rating_for_movie(movie_name: str) -> Rating:\n",
    "    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        rating = give_rating_for_movie(\"Die Hard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler(num_retries=3)):\n",
    "    rating = give_rating_for_movie(\"Die Hard\")\n",
    "    print(f\"Score: {rating.score}/5\")\n",
    "    print(f\"Explanation: {rating.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0632c",
   "metadata": {},
   "source": [
    "## Generating higher-order functions\n",
    "Finally, we can generate higher-order functions that can call templates as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'summarize_doctest', 'count_char_with_bad_doctest', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'unstable_service', 'fetch_data', 'give_rating_for_movie', 'write_chapter', 'judge_chapter'])\n",
      "=== Story with moral ===\n",
      "def write_moral_story(topic: str) -> str:\n",
      "    story_parts = []\n",
      "    chapter_number = 1\n",
      "    chapter_names = [\"Beginning\", \"Middle\", \"Climax\", \"Conclusion\"]\n",
      "    \n",
      "    for chapter_name in chapter_names:\n",
      "        current_chapter = write_chapter(chapter_number, chapter_name)\n",
      "        story_parts.append(current_chapter)\n",
      "        if not judge_chapter(' '.join(story_parts), chapter_number):\n",
      "            raise ValueError(f\"Chapter {chapter_number} is not coherent with the story so far.\")\n",
      "        chapter_number += 1\n",
      "    \n",
      "    full_story = ' '.join(story_parts)\n",
      "    return full_story\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Chapter 2 is not coherent with the story so far.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m function_that_writes_story = write_multi_chapter_story(\u001b[33m\"\u001b[39m\u001b[33mmoral\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(inspect.getsource(function_that_writes_story))\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfunction_that_writes_story\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43ma curious cat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<synthesis:4969049760>:12\u001b[39m, in \u001b[36mwrite_moral_story\u001b[39m\u001b[34m(topic)\u001b[39m\n\u001b[32m     10\u001b[39m     story_parts.append(current_chapter)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m judge_chapter(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(story_parts), chapter_number):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChapter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchapter_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is not coherent with the story so far.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m     chapter_number += \u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m full_story = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(story_parts)\n",
      "\u001b[31mValueError\u001b[39m: Chapter 2 is not coherent with the story so far."
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def write_chapter(chapter_number: int, chapter_name: str) -> str:\n",
    "    \"\"\"Write a short story about {chapter_number}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def judge_chapter(story_so_far: str, chapter_number: int) -> bool:\n",
    "    \"\"\"Decide if the new chapter is coherence with the story so far. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_multi_chapter_story(style: Literal[\"moral\", \"funny\"]) -> Callable[[str], str]:\n",
    "    \"\"\"Generate a function that writes a story in style: {style} about the given topic.\n",
    "    Try to return the story no matter what.\n",
    "\n",
    "    The program can use helper functions defined elsewhere (DO NOT REDEFINE THEM):\n",
    "    - write_chapter(chapter_number: int, chapter_name: str) -> str\n",
    "    - judge_chapter(story_so_far: str, chapter_number: int) -> bool\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "print(\"Sub-templates available to write_story:\", write_multi_chapter_story.tools.keys())\n",
    "\n",
    "with (\n",
    "    handler(RetryLLMHandler(num_retries=3)),\n",
    "    handler(provider),\n",
    "    handler(UnsafeEvalProvider()),\n",
    "):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    function_that_writes_story = write_multi_chapter_story(\"moral\")\n",
    "    print(inspect.getsource(function_that_writes_story))\n",
    "    print(function_that_writes_story(\"a curious cat\"))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
