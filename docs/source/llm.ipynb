{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fda1b8",
   "metadata": {},
   "source": [
    "# LLM Interface\n",
    "The `effectful.handlers.llm` module provides a simplified LLM interface that uses algebraic effects for modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `Template.define` which creates a prompt template from a callable. A template is an LLM-implemented function whose behavior is specified by a template string. When a template is called, an LLM is invoked to produce the specified behavior.\n",
    "- A decorator `Tool.define` which exposes Python callables as tools that templates can call. Tool signatures and docstrings define the schema passed to the model.\n",
    "- Structured output handling via `Encodable` (used internally by templates and tool calls) to serialize/deserialize Python types.\n",
    "- LLM providers such as `LiteLLMProvider`, and reliability helpers like `RetryLLMHandler` and `ReplayLiteLLMProvider`, which can be composed with `handler(...)` to control execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import dataclasses\n",
    "import functools\n",
    "import io\n",
    "from typing import Literal\n",
    "\n",
    "import litellm\n",
    "import pydantic\n",
    "from IPython.display import HTML, display\n",
    "from litellm.caching.caching import Cache\n",
    "from PIL import Image\n",
    "from pydantic import field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "from effectful.handlers.llm import Agent, Template, Tool\n",
    "from effectful.handlers.llm.completions import (\n",
    "    LiteLLMProvider,\n",
    "    RetryLLMHandler,\n",
    ")\n",
    "from effectful.ops.semantics import NotHandled, handler\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093243e0",
   "metadata": {},
   "source": [
    "In the following sections, we walk through each of the mentioned components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the sea where the little fish swim,  \n",
      "One fish thought heâ€™d try to be slim.  \n",
      "Heâ€™d wiggle and dash,  \n",
      "In hopes of a splash,  \n",
      "But found he was chubby and prim.\n",
      "----------------------------------------\n",
      "In the deep blue sea swam a trout,  \n",
      "Who loved to leap and jump about.  \n",
      "With scales all aglitter,  \n",
      "It danced with a flitter,  \n",
      "And got in a whale's belly without a doubt!  \n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or use LiteLLM's built-in cache by setting a cache backend and passing `caching=True` to the provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silver scales in streams,  \n",
      "Glide through currents, swift and free,  \n",
      "Water whispers peace.\n",
      "----------------------------------------\n",
      "Silver scales in streams,  \n",
      "Glide through currents, swift and free,  \n",
      "Water whispers peace.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendat/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content=\"Gentle f...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gentle fish glides through,  \n",
      "Ripples dance on water's face,  \n",
      "Silent grace below.  \n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendat/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content=\"Swimming...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swimming in water,  \n",
      "Silent scales glimmer like stars,  \n",
      "Ocean's gentle grace.\n",
      "\n",
      "In the clear pond's gleam,  \n",
      "Silent fish weave through light streams,  \n",
      "Nature's whispered dream.\n",
      "----------------------------------------\n",
      "Silver scales glisten,  \n",
      "Silent streams embrace their dance,  \n",
      "Nature's tranquil grace.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "# Enable LiteLLM caching by setting a cache backend and enabling caching.\n",
    "litellm.cache = Cache()\n",
    "provider_cached = LiteLLMProvider(caching=True)\n",
    "try:\n",
    "    with handler(provider_cached):\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "        print(\"-\" * 40)\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "finally:\n",
    "    litellm.cache = None\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. Callable synthesis is supported via `Encodable` and the evaluation providers in `effectful.handlers.llm.evaluation` (`UnsafeEvalProvider` or `RestrictedEvalProvider`), which enable parsing/compiling/executing synthesized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_a(input_string: str) -> int:\n",
      "    \"\"\"\n",
      "    Counts the occurrences of the letter 'a' in the given string.\n",
      "\n",
      "    :param input_string: The string to search for 'a' characters.\n",
      "    :return: The count of 'a' characters in the string.\n",
      "    \"\"\"\n",
      "    count = 0\n",
      "    for char in input_string:\n",
      "        if char == 'a':\n",
      "            count += 1\n",
      "    return count\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from collections.abc import Callable\n",
    "\n",
    "from effectful.handlers.llm.evaluation import UnsafeEvalProvider\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Use UnsafeEvalProvider for simple examples; RestrictedEvalProvider may need extra globals.\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the current weather conditions, Barcelona has good weather as it is currently sunny.\n"
     ]
    }
   ],
   "source": [
    "@Tool.define\n",
    "def cities() -> list[str]:\n",
    "    \"\"\"Return a list of cities that can be passed to `weather`.\"\"\"\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Given a city name, return a description of the weather in that city.\"\"\"\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59584a54",
   "metadata": {},
   "source": [
    "## Image Inputs\n",
    "\n",
    "You can pass `PIL.Image.Image` values directly to templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89992702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqAMAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQAmgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\" alt=\"Example image\" width=\"320\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a simple yellow smiley face with black eyes and a curved mouth, set against a bright yellow background.\n"
     ]
    }
   ],
   "source": [
    "image_base64 = (\n",
    "    \"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqA\"\n",
    "    \"MAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg\"\n",
    "    \"+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQA\"\n",
    "    \"mgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\"\n",
    ")\n",
    "image = Image.open(io.BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def describe_image(image: Image.Image) -> str:\n",
    "    \"\"\"Return a short description of the following image.\n",
    "    {image}\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Example image\" width=\"320\" />'\n",
    "        )\n",
    "    )\n",
    "    print(describe_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Lizard.\n",
      "Lizard who?\n",
      "Lizard who? Lizard you can do, I can do better!\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny'])\n",
      "=== Story with moral ===\n",
      "Here's a story about a curious cat named Whiskers who embarked on an adventurous journey, only to learn an important lesson about the balance between curiosity and caution. \n",
      "\n",
      "In his quest to follow a mesmerizing butterfly, Whiskers ventured far from home, enchanted by the beauty of nature. Along the way, he encountered a wise old owl who reminded him of the importance of being mindful of his surroundings. Whiskers returned home with newfound wisdom, realizing that while curiosity can lead to wonderful discoveries, it's essential to remain aware and cautious to avoid getting lost.\n",
      "\n",
      "**Moral of the story: Curiosity can lead to remarkable discoveries, but always remember to explore with awareness and caution to avoid losing your way.**\n",
      "\n",
      "=== Funny story ===\n",
      "Once upon a time in a cozy little town, there lived a cat named Whiskers. Whiskers wasn't your ordinary feline; he was endowed with insatiable curiosity and an unerring sense of mischief. His favorite pastime was sneaking around his neighborhood, peeking into every nook and cranny, much to the chagrin of the townspeople.\n",
      "\n",
      "Whiskers' latest adventure began when he spotted a shiny object inside Mr. Johnson's garage. The door was slightly ajar, just enough for a slender cat to slip through. Of course, he couldn't resist the temptation. With a twitch of his tail and a playful leap, Whiskers was inside.\n",
      "\n",
      "As soon as he entered, he was faced with the most peculiar sightâ€”an old automatic vacuum cleaner. To Whiskers, this was no ordinary device. He saw it as a mysterious, growling beast that needed to be conquered. With a mighty pounce, he landed squarely on top of it. Unfortunately for Whiskers, he had activated the vacuum, sending it whirring around the garage with him clinging for dear life.\n",
      "\n",
      "The â€œwild rideâ€ that ensued was a scene to behold. The vacuum zoomed forward, backward, and in crazy circles, causing Mr. Johnsonâ€™s carefully stacked boxes to tumble down like dominoes. Paint cans rattled, and a garden gnome was knocked over, all while Whiskers' fur stood on end with a mixture of excitement and terror.\n",
      "\n",
      "Hearing the commotion, Mrs. Johnson rushed to the garage, expecting to find some sort of intruder. Instead, she found Whiskers riding the chaos-inducing vacuum. With laughter bubbling up, she quickly turned off the machine, releasing a very dizzy kitty.\n",
      "\n",
      "Whiskers stumbled off, shook his furry head, and gave Mrs. Johnson a look that seemed to say, \"I totally meant to do that.\" She couldn't help but laugh and gave Whiskers a good scratch behind the ears as a reward for his bravery.\n",
      "\n",
      "After this hair-raising adventure, Whiskers promised himself to stay out of the Johnsons' garage, at least for a day or two. Instead, he decided to take a nap in a sunbeam, where the only danger was a dream about chasing more imaginary beasts.\n",
      "\n",
      "And so, in the little town, Whiskers cemented his reputation as the cat who tamed the wild, untamable vacuum, and the townsfolk couldn't wait to see what this curious feline would do next.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools.values()\n",
    "assert story_funny in write_story.tools.values()\n",
    "print(\"Sub-templates available to write_story:\", write_story.tools.keys())\n",
    "\n",
    "with handler(provider):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z7yy72fumf",
   "metadata": {},
   "source": [
    "## Agents and Lexical Scoping\n",
    "\n",
    "`Agent` serves as a natural mechanism for encapsulating Templates and Tools into disjoint sets. Because templates capture tools from their **lexical scope** (following Python's ordinary scoping rules), templates on one agent instance cannot see templates on another instance â€” unless they are explicitly in scope.\n",
    "\n",
    "This means:\n",
    "- An agent's methods see sibling methods on the same instance (via `self`) and any tools defined in enclosing scopes.\n",
    "- Templates defined inside a function body see local variables in that function, but not variables from other function bodies.\n",
    "- A top-level orchestrator template can reference multiple agents, while those agents' own methods remain isolated from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sk04iylc4vh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot.respond tools: ['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'self__greet']\n",
      "simulate_user_interaction tools: ['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'chatbot__respond', 'chatbot__greet', 'another_chatbot__respond', 'another_chatbot__greet', 'travel_advisor__recommend_destination', 'travel_advisor__search_weather']\n",
      "Hello there! ðŸŒŸ It's wonderful to have you here. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "class Chatbot(Agent):\n",
    "    \"\"\"You are a friendly chatbot.\"\"\"\n",
    "\n",
    "    @Template.define\n",
    "    def respond(self, user_query: str) -> str:\n",
    "        \"\"\"Respond to the user's query: {user_query}.\"\"\"\n",
    "        raise NotHandled\n",
    "\n",
    "    @Template.define\n",
    "    def greet(self, user_name: str) -> str:\n",
    "        \"\"\"Greet {user_name} warmly.\"\"\"\n",
    "        raise NotHandled\n",
    "\n",
    "\n",
    "class TravelAdvisor(Agent):\n",
    "    \"\"\"You are a travel advisor.\"\"\"\n",
    "\n",
    "    @Template.define\n",
    "    def recommend_destination(self, user_query: str) -> str:\n",
    "        \"\"\"Recommend a travel destination based on {user_query}.\"\"\"\n",
    "        raise NotHandled\n",
    "\n",
    "    @Tool.define\n",
    "    def search_weather(self, city: str) -> str:\n",
    "        \"\"\"Search the weather for a given city.\"\"\"\n",
    "        return {\"Paris\": \"sunny\", \"London\": \"rainy\"}.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    chatbot = Chatbot()\n",
    "    another_chatbot = Chatbot()\n",
    "    travel_advisor = TravelAdvisor()\n",
    "\n",
    "    @Template.define\n",
    "    def simulate_user_interaction() -> str:\n",
    "        \"\"\"Use {another_chatbot} and {travel_advisor} to simulate an interaction between a user and assistant.\"\"\"\n",
    "        raise NotHandled\n",
    "\n",
    "    # chatbot.respond sees write_poem (enclosing module scope) and chatbot.greet (sibling via self),\n",
    "    # but NOT another_chatbot's or travel_advisor's methods (different lexical scope).\n",
    "    assert \"self__greet\" in chatbot.respond.tools\n",
    "    assert \"self__recommend_destination\" not in chatbot.respond.tools\n",
    "\n",
    "    # simulate_user_interaction sees all agents (they're local variables in main),\n",
    "    # but none of those agents' methods can see simulate_user_interaction.\n",
    "    assert \"another_chatbot__respond\" in simulate_user_interaction.tools\n",
    "    assert \"travel_advisor__recommend_destination\" in simulate_user_interaction.tools\n",
    "    assert \"simulate_user_interaction\" not in chatbot.respond.tools\n",
    "\n",
    "    print(\"chatbot.respond tools:\", list(chatbot.respond.tools.keys()))\n",
    "    print(\"simulate_user_interaction tools:\", list(simulate_user_interaction.tools.keys()))\n",
    "    \n",
    "    with handler(provider):\n",
    "        print(simulate_user_interaction())\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3g84db95wof",
   "metadata": {},
   "source": [
    "In this example, `chatbot.respond` has access to `write_poem` (module scope) and `chatbot.greet` (sibling method via `self`), but **not** to `another_chatbot.respond` or `travel_advisor.recommend_destination`. Meanwhile, `simulate_user_interaction` (defined inside `main`) can see `chatbot`, `another_chatbot`, and `travel_advisor`, but none of those agents' methods can see it back.\n",
    "\n",
    "This is exactly the behavior you'd expect for ordinary Python objects â€” if `Chatbot.respond` were an ordinary instance method, it wouldn't have access to lexical variables in the body of `main`.\n",
    "\n",
    "In contrast, if the body of `main` were inlined into the top-level module scope (where `Chatbot` and `TravelAdvisor` are defined), this encapsulation would be broken and all the templates would see all of the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": [
    "## Retrying LLM Requests\n",
    "LLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls and can also surface tool/runtime errors as tool messages:\n",
    "\n",
    "- `include_traceback`: When `True`, include traceback details in the error feedback (default: True)\n",
    "- `catch_tool_errors`: Exception type(s) to catch during tool execution (default: `Exception`)\n",
    "- `**kwargs`: Additional keyword arguments forwarded to `tenacity.Retrying` (defaults: `stop=stop_after_attempt(4)`, `wait=wait_none()`, `reraise=True`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Tool execution failed: Error executing tool 'unstable_service': Service unavailable! Attempt 1/3. Please retry.\n",
      "Result: I successfully fetched the data: `[1, 2, 3]`. Retries: 3\n"
     ]
    }
   ],
   "source": [
    "call_count = 0\n",
    "REQUIRED_RETRIES = 3\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def unstable_service() -> str:\n",
    "    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if call_count < REQUIRED_RETRIES:\n",
    "        raise ConnectionError(\n",
    "            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n",
    "        )\n",
    "    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n",
    "\n",
    "\n",
    "@Template.define  # unstable_service auto-captured from lexical scope\n",
    "def fetch_data() -> str:\n",
    "    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        result = fetch_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler()):\n",
    "    result = fetch_data()\n",
    "    print(f\"Result: {result}\", \"Retries:\", call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "## Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error decoding response: 1 validation error for Response_Rating\n",
      "value.score\n",
      "  score must be 1â€“5, got 9 [type=invalid_score, input_value=9, input_type=int]. Please provide a valid response and try again.\n",
      "Score: 5/5\n",
      "Explanation: Die Hard is a timeless action film that stands out for its tight storytelling, engaging action scenes, and memorable performances. The movie effectively combines suspense, humor, and character development, making it a beloved classic in the action genre. Given its impact and quality, I would rate it a 5 out of 5.\n"
     ]
    }
   ],
   "source": [
    "@pydantic.dataclasses.dataclass\n",
    "class Rating:\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "    @field_validator(\"score\")\n",
    "    @classmethod\n",
    "    def check_score(cls, v):\n",
    "        if v < 1 or v > 5:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_score\",\n",
    "                \"score must be 1â€“5, got {v}\",\n",
    "                {\"v\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"explanation\")\n",
    "    @classmethod\n",
    "    def check_explanation_contains_score(cls, v, info):\n",
    "        score = info.data.get(\"score\", None)\n",
    "        if score is not None and str(score) not in v:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_explanation\",\n",
    "                \"explanation must mention the score {score}, got '{explanation}'\",\n",
    "                {\"score\": score, \"explanation\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def give_rating_for_movie(movie_name: str) -> Rating:\n",
    "    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        rating = give_rating_for_movie(\"Die Hard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler()):\n",
    "    rating = give_rating_for_movie(\"Die Hard\")\n",
    "    print(f\"Score: {rating.score}/5\")\n",
    "    print(f\"Explanation: {rating.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0632c",
   "metadata": {},
   "source": [
    "## Generating higher-order functions\n",
    "Finally, we can generate higher-order functions that can call templates as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d02bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'unstable_service', 'fetch_data', 'give_rating_for_movie', 'write_chapter', 'judge_chapter'])\n",
      "=== Story with moral ===\n",
      "def write_moral_story(topic: str) -> str:\n",
      "    story = \"\"  # Initialize an empty story string\n",
      "    chapter_number = 1  # Start with the first chapter\n",
      "    \n",
      "    while True:\n",
      "        chapter_name = f\"Chapter {chapter_number}: {topic}\"\n",
      "        try:\n",
      "            chapter_text = write_chapter(chapter_number, chapter_name)\n",
      "            story += chapter_text + \"\\n\"\n",
      "            \n",
      "            if not judge_chapter(story, chapter_number):\n",
      "                break\n",
      "            \n",
      "            chapter_number += 1  # Move to the next chapter\n",
      "        except Exception as e:\n",
      "            # Handle any exceptions raised by the helper functions\n",
      "            return f\"An error occurred while trying to write the story: {str(e)}\"\n",
      "    \n",
      "    return story\n",
      "\n",
      "Once upon a time in the small, quaint village of Numeria, there was a mysterious legend surrounding the number \"1.\" It was believed to be the most powerful and significant number in existence, the origin of all numbers and the building block of the universe.\n",
      "\n",
      "The villagers worshipped the number \"1\" with great reverence, attributing it to unity, beginnings, and singularity. They celebrated a special festival each year called \"Uno Fest\" to honor this special number. At the center of the festival was a magical ceremony where they would light a single candle, representing the oneness of life.\n",
      "\n",
      "On the eve of the current year's Uno Fest, a young boy named Eli was curious to discover the true power of the number \"1.\" Eli believed that if he could understand its power, he could bring joy and prosperity to everyone in the village. He wandered into the forest, known for its mystical aura, hoping to find answers.\n",
      "\n",
      "As he ventured deeper into the woods, Eli stumbled upon an ancient stone tablet inscribed with the symbol \"1.\" As he touched it, a wise old spirit appeared. \"Young Eli,\" the spirit spoke gently, \"what do you seek?\" Eli replied, \"I want to understand the true power of '1.'\"\n",
      "\n",
      "The spirit smiled and began to explain, \"The power of '1' lies not in its numerical value, but in its meaning. It is the essence of unity and the beginning of everything. It symbolizes the potential in new beginnings and the importance of staying true to oneself. Every great journey begins with one single step.\"\n",
      "\n",
      "Inspired by the spirit's words, Eli returned to the village filled with newfound wisdom. At the Uno Fest, he shared his experience with the villagers, preaching the importance of unity and the power within each of them to make a positive difference. The festival of celebration turned into a day of reflection and unity, solidifying the village's bond.\n",
      "\n",
      "And so, the legend of the number \"1\" continued, carrying forward the eternal truth that every great achievement starts with a single, powerful step. Eli's journey reminded everyone in Numeria that they, too, had the power to begin anew, united in their strength and purpose. The moral of the story was clear: In unity, there is strength, and every great journey begins with one small step.\n",
      "As the first rays of the sun began to peek over the horizon, an old clockmaker named Elias woke up in the small village of Havenwood. Elias had lived in the village all his life, surrounded by ticking clocks and the gentle hum of their mechanisms. Each clock in his shop was a testament to his craftsmanship and passion.\n",
      "\n",
      "Elias had a special fondness for the number 2, considering it his lucky number. All his life, he noticed that significant events happened in pairs: two opportunities to become a clockmaker, two chances to meet the love of his life, and eventually two beautiful children. He often mused, \"Things come in pairs for a reason.\"\n",
      "\n",
      "One fine morning, as Elias was dusting and winding the clocks in his shop, he stumbled upon an old, dusty wooden box. The box wasn't remarkable in appearance, but when Elias opened it, he found two identical pocket watches, each intricately designed with silver filigree and an unmistakable engraving of a pair of doves. How these watches ended up in the shop was a mystery, but Elias decided to restore them.\n",
      "\n",
      "Days turned into weeks, and Elias worked meticulously on the pocket watches. He polished every surface, repaired the delicate gears, and reattached the hands. Upon completion, he marveled at their beauty and symmetryâ€”two perfect creations reflecting his life's philosophy.\n",
      "\n",
      "As fate would have it, a traveler visited Havenwood and was drawn to Eliasâ€™s shop. The traveler, a young woman named Amelia, was captivated by the twinsâ€™ watches. She explained that she was on a journey to find something significant, something that spoke to her heart.\n",
      "\n",
      "Elias, sensing the unique connection between the watches and this traveler, shared their story. He spoke of his life of dualities and how everything always seemed to come in pairs, especially the most meaningful elements. Touched by his tale, Amelia purchased both watches, declaring one would be for her and the other for her twin sister, whom she had not seen in years.\n",
      "\n",
      "As Amelia left the shop, Elias felt a surge of contentment. He realized that his belief in the power of two was not just a whimsical notion, but a living testament to the interconnectedness of lives and the potential of renewed connections.\n",
      "\n",
      "Amelia's story and the paired watchesâ€™ journey reminded Elias of the simple truth: that sometimes, things are meant to be foundâ€”not alone, but together. Whether it was pairs of events or connections, the number 2 would always hold a special place in the heart of a humble clockmaker who saw symmetry and significance in every ticking second.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def write_chapter(chapter_number: int, chapter_name: str) -> str:\n",
    "    \"\"\"Write a short story about {chapter_number}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def judge_chapter(story_so_far: str, chapter_number: int) -> bool:\n",
    "    \"\"\"Decide if the new chapter is coherence with the story so far. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_multi_chapter_story(style: Literal[\"moral\", \"funny\"]) -> Callable[[str], str]:\n",
    "    \"\"\"Generate a function that writes a story in style: {style} about the given topic.\n",
    "\n",
    "    If you raise exception, handle it yourself.\n",
    "    The program can use helper functions defined elsewhere (DO NOT REDEFINE THEM):\n",
    "    - write_chapter(chapter_number: int, chapter_name: str) -> str\n",
    "    - judge_chapter(story_so_far: str, chapter_number: int) -> bool\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "print(\"Sub-templates available to write_story:\", write_multi_chapter_story.tools.keys())\n",
    "\n",
    "with (\n",
    "    handler(RetryLLMHandler()),\n",
    "    handler(provider),\n",
    "    handler(UnsafeEvalProvider()),\n",
    "):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    function_that_writes_story = write_multi_chapter_story(\"moral\")\n",
    "    print(inspect.getsource(function_that_writes_story))\n",
    "    print(function_that_writes_story(\"a curious cat\"))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
