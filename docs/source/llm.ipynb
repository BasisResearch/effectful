{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fda1b8",
   "metadata": {},
   "source": [
    "# LLM Interface\n",
    "The `effectful.handlers.llm` module provides a simplified LLM interface that uses algebraic effects for modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `Template.define` which creates a prompt template from a callable. A template is an LLM-implemented function whose behavior is specified by a template string. When a template is called, an LLM is invoked to produce the specified behavior.\n",
    "- A decorator `Tool.define` which exposes Python callables as tools that templates can call. Tool signatures and docstrings define the schema passed to the model.\n",
    "- Structured output handling via `Encodable` (used internally by templates and tool calls) to serialize/deserialize Python types.\n",
    "- LLM providers such as `LiteLLMProvider`, and reliability helpers like `RetryLLMHandler` and `ReplayLiteLLMProvider`, which can be composed with `handler(...)` to control execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import dataclasses\n",
    "import functools\n",
    "import io\n",
    "from typing import Literal\n",
    "\n",
    "import litellm\n",
    "import pydantic\n",
    "from IPython.display import HTML, display\n",
    "from litellm.caching.caching import Cache\n",
    "from PIL import Image\n",
    "from pydantic import field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "from effectful.handlers.llm import Template, Tool\n",
    "from effectful.handlers.llm.completions import (\n",
    "    LiteLLMProvider,\n",
    "    RetryLLMHandler,\n",
    ")\n",
    "from effectful.ops.semantics import NotHandled, handler\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093243e0",
   "metadata": {},
   "source": [
    "In the following sections, we walk through each of the mentioned components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the ocean so deep and so wide,\n",
      "There's a fish with a fin full of pride.\n",
      "He swims with a gleam,\n",
      "In a school like a dream,\n",
      "As they wander the blue, side by side.\n",
      "----------------------------------------\n",
      "In the depths of the sea, fish frolic with glee,\n",
      "From goldfish to salmon, they're ever so free.\n",
      "They swim and they dart,\n",
      "Each plays its own part,\n",
      "Underneath waves, they carelessly spree.\n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or use LiteLLM's built-in cache by setting a cache backend and passing `caching=True` to the provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Swim in silent streams,\n",
      "Scales gleam under moonlit glow—\n",
      "River's whispered dreams.\n",
      "----------------------------------------\n",
      "Swim in silent streams,\n",
      "Scales gleam under moonlit glow—\n",
      "River's whispered dreams.\n",
      "\n",
      "Silver scales glisten,\n",
      "Beneath the ocean's whisper—  \n",
      "Silent fins dance deep.\n",
      "----------------------------------------\n",
      "In ocean's vast depth,  \n",
      "Gliding through the watery world,  \n",
      "Fish dance with the waves.\n",
      "\n",
      "Fish swim with grace, free—\n",
      "In vast blue ocean they glide,\n",
      "Silent in their world.\n",
      "----------------------------------------\n",
      "In tranquil waters,\n",
      "Silver scales shimmer and dart—\n",
      "Silent fish dance swift.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "# Enable LiteLLM caching by setting a cache backend and enabling caching.\n",
    "litellm.cache = Cache()\n",
    "provider_cached = LiteLLMProvider(caching=True)\n",
    "try:\n",
    "    with handler(provider_cached):\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "        print(\"-\" * 40)\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "finally:\n",
    "    litellm.cache = None\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. Callable synthesis is supported via `Encodable` and the evaluation providers in `effectful.handlers.llm.evaluation` (`UnsafeEvalProvider` or `RestrictedEvalProvider`), which enable parsing/compiling/executing synthesized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_a_occurrences(input_string: str) -> int:\n",
      "    \"\"\"\n",
      "    Count the occurrences of the letter 'a' in a given string.\n",
      "\n",
      "    :param input_string: The string to search within.\n",
      "    :return: The number of times 'a' appears in the string.\n",
      "    \"\"\"\n",
      "    return input_string.count('a')\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from collections.abc import Callable\n",
    "\n",
    "from effectful.handlers.llm.evaluation import UnsafeEvalProvider\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Use UnsafeEvalProvider for simple examples; RestrictedEvalProvider may need extra globals.\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the weather conditions:\n",
      "\n",
      "- **Chicago** is currently cold.\n",
      "- **New York** is currently wet.\n",
      "- **Barcelona** is currently sunny.\n",
      "\n",
      "I suggest **Barcelona** as the city with good weather.\n"
     ]
    }
   ],
   "source": [
    "@Tool.define\n",
    "def cities() -> list[str]:\n",
    "    \"\"\"Return a list of cities that can be passed to `weather`.\"\"\"\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Given a city name, return a description of the weather in that city.\"\"\"\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59584a54",
   "metadata": {},
   "source": [
    "## Image Inputs\n",
    "\n",
    "You can pass `PIL.Image.Image` values directly to templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89992702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqAMAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQAmgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\" alt=\"Example image\" width=\"320\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple smiley face with a yellow background, featuring two black dots for eyes and a curved line for a mouth, typically used to convey happiness or friendliness.\n"
     ]
    }
   ],
   "source": [
    "image_base64 = (\n",
    "    \"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqA\"\n",
    "    \"MAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg\"\n",
    "    \"+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQA\"\n",
    "    \"mgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\"\n",
    ")\n",
    "image = Image.open(io.BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def describe_image(image: Image.Image) -> str:\n",
    "    \"\"\"Return a short description of the following image.\n",
    "    {image}\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Example image\" width=\"320\" />'\n",
    "        )\n",
    "    )\n",
    "    print(describe_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Lizard.\n",
      "Lizard who?\n",
      "Lizard who? Lizard you wonder, there's a gecko at your door!\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['describe_image', 'draw_simple_icon', 'limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny'])\n",
      "=== Story with moral ===\n",
      "\n",
      "\n",
      "In the case of Whiskers, it was his understanding of this balance that brought him safely home, with both stories and lessons to cherish and share.\n",
      "\n",
      "=== Funny story ===\n",
      "\n",
      "\n",
      "The End.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools.values()\n",
    "assert story_funny in write_story.tools.values()\n",
    "print(\"Sub-templates available to write_story:\", write_story.tools.keys())\n",
    "\n",
    "with handler(provider):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": "## Retrying LLM Requests\nLLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls and can also surface tool/runtime errors as tool messages:\n\n- `include_traceback`: When `True`, include traceback details in the error feedback (default: True)\n- `catch_tool_errors`: Exception type(s) to catch during tool execution (default: `Exception`)\n- `**kwargs`: Additional keyword arguments forwarded to `tenacity.Retrying` (defaults: `stop=stop_after_attempt(4)`, `wait=wait_none()`, `reraise=True`)\n"
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [],
   "source": "call_count = 0\nREQUIRED_RETRIES = 3\n\n\n@Tool.define\ndef unstable_service() -> str:\n    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n    global call_count\n    call_count += 1\n    if call_count < REQUIRED_RETRIES:\n        raise ConnectionError(\n            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n        )\n    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n\n\n@Template.define  # unstable_service auto-captured from lexical scope\ndef fetch_data() -> str:\n    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n    raise NotHandled\n\n\nwith handler(provider):\n    try:\n        result = fetch_data()\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nwith handler(provider), handler(RetryLLMHandler()):\n    result = fetch_data()\n    print(f\"Result: {result}\", \"Retries:\", call_count)"
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "## Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [],
   "source": "@pydantic.dataclasses.dataclass\nclass Rating:\n    score: int\n    explanation: str\n\n    @field_validator(\"score\")\n    @classmethod\n    def check_score(cls, v):\n        if v < 1 or v > 5:\n            raise PydanticCustomError(\n                \"invalid_score\",\n                \"score must be 1–5, got {v}\",\n                {\"v\": v},\n            )\n        return v\n\n    @field_validator(\"explanation\")\n    @classmethod\n    def check_explanation_contains_score(cls, v, info):\n        score = info.data.get(\"score\", None)\n        if score is not None and str(score) not in v:\n            raise PydanticCustomError(\n                \"invalid_explanation\",\n                \"explanation must mention the score {score}, got '{explanation}'\",\n                {\"score\": score, \"explanation\": v},\n            )\n        return v\n\n\n@Template.define\ndef give_rating_for_movie(movie_name: str) -> Rating:\n    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n    raise NotHandled\n\n\nwith handler(provider):\n    try:\n        rating = give_rating_for_movie(\"Die Hard\")\n    except Exception as e:\n        print(f\"Error: {e}\")\n\nwith handler(provider), handler(RetryLLMHandler()):\n    rating = give_rating_for_movie(\"Die Hard\")\n    print(f\"Score: {rating.score}/5\")\n    print(f\"Explanation: {rating.explanation}\")"
  },
  {
   "cell_type": "markdown",
   "id": "aec0632c",
   "metadata": {},
   "source": [
    "## Generating higher-order functions\n",
    "Finally, we can generate higher-order functions that can call templates as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d02bc67",
   "metadata": {},
   "outputs": [],
   "source": "# Sub-templates for different story styles\n@Template.define\ndef write_chapter(chapter_number: int, chapter_name: str) -> str:\n    \"\"\"Write a short story about {chapter_number}. Do not use any tools.\"\"\"\n    raise NotHandled\n\n\n@Template.define\ndef judge_chapter(story_so_far: str, chapter_number: int) -> bool:\n    \"\"\"Decide if the new chapter is coherence with the story so far. Do not use any tools.\"\"\"\n    raise NotHandled\n\n\n# Main orchestrator template - has access to sub-templates\n@Template.define\ndef write_multi_chapter_story(style: Literal[\"moral\", \"funny\"]) -> Callable[[str], str]:\n    \"\"\"Generate a function that writes a story in style: {style} about the given topic.\n\n    The program can use helper functions defined elsewhere (DO NOT REDEFINE THEM):\n    - write_chapter(chapter_number: int, chapter_name: str) -> str\n    - judge_chapter(story_so_far: str, chapter_number: int) -> bool\"\"\"\n    raise NotHandled\n\n\n# Verify sub-templates are captured in write_story's lexical context\nprint(\"Sub-templates available to write_story:\", write_multi_chapter_story.tools.keys())\n\nwith (\n    handler(RetryLLMHandler()),\n    handler(provider),\n    handler(UnsafeEvalProvider()),\n):\n    print(\"=== Story with moral ===\")\n    function_that_writes_story = write_multi_chapter_story(\"moral\")\n    print(inspect.getsource(function_that_writes_story))\n    print(function_that_writes_story(\"a curious cat\"))\n    print()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}