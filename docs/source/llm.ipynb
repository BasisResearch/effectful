{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fda1b8",
   "metadata": {},
   "source": [
    "# LLM Interface\n",
    "The `effectful.handlers.llm` module provides a simplified LLM interface that uses algebraic effects for modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `Template.define` which creates a prompt template from a callable. A template is an LLM-implemented function whose behavior is specified by a template string. When a template is called, an LLM is invoked to produce the specified behavior.\n",
    "- A decorator `Tool.define` which exposes Python callables as tools that templates can call. Tool signatures and docstrings define the schema passed to the model.\n",
    "- Structured output handling via `Encodable` (used internally by templates and tool calls) to serialize/deserialize Python types.\n",
    "- LLM providers such as `LiteLLMProvider`, and reliability helpers like `RetryLLMHandler` and `ReplayLiteLLMProvider`, which can be composed with `handler(...)` to control execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import dataclasses\n",
    "import functools\n",
    "import inspect\n",
    "import io\n",
    "from collections.abc import Callable\n",
    "from typing import Literal\n",
    "\n",
    "import litellm\n",
    "import pydantic\n",
    "from IPython.display import HTML, display\n",
    "from litellm.caching.caching import Cache\n",
    "from PIL import Image\n",
    "from pydantic import field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "from effectful.handlers.llm import Template, Tool\n",
    "from effectful.handlers.llm.completions import (\n",
    "    LiteLLMProvider,\n",
    "    RetryLLMHandler,\n",
    ")\n",
    "from effectful.handlers.llm.evaluation import DoctestHandler, UnsafeEvalProvider\n",
    "from effectful.ops.semantics import NotHandled, handler\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093243e0",
   "metadata": {},
   "source": [
    "In the following sections, we walk through each of the mentioned components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the ocean where brightly fish swim,\n",
      "They dance with a graceful, sleek trim.\n",
      "With scales that do shimmer,\n",
      "They dart and they glimmer,\n",
      "In the deep where the light is dim.\n",
      "----------------------------------------\n",
      "In the sea swam a fish with delight,\n",
      "Who glowed with a silvery light.\n",
      "He danced in the waves,\n",
      "Through coral-caved graves,\n",
      "A master of day and of night.\n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or use LiteLLM's built-in cache by setting a cache backend and passing `caching=True` to the provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beneath silver waves,  \n",
      "Fish dance in liquid sunlight,  \n",
      "Silent world abides.\n",
      "----------------------------------------\n",
      "Beneath silver waves,  \n",
      "Fish dance in liquid sunlight,  \n",
      "Silent world abides.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendat/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='{\"value\"...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whispers of rivers,\n",
      "Scales shimmer like the sunrise,\n",
      "Silent fins glide by.\n",
      "----------------------------------------\n",
      "Gentle waves ripple,  \n",
      "Underwater world whispers,  \n",
      "Fish dance in silence.\n",
      "\n",
      "Fish swim in clear streams,  \n",
      "Scales shimmer under sunlight,  \n",
      "Quietly they glide.\n",
      "----------------------------------------\n",
      "In deep ocean blue,\n",
      "Silent fins weave through currents,\n",
      "Whispers of the deep.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "# Enable LiteLLM caching by setting a cache backend and enabling caching.\n",
    "litellm.cache = Cache()\n",
    "provider_cached = LiteLLMProvider(caching=True)\n",
    "try:\n",
    "    with handler(provider_cached):\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "        print(\"-\" * 40)\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "finally:\n",
    "    litellm.cache = None\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. Callable synthesis is supported via `Encodable` and the evaluation providers in `effectful.handlers.llm.evaluation` (`UnsafeEvalProvider` or `RestrictedEvalProvider`), which enable parsing/compiling/executing synthesized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_char(s: str) -> int:\n",
      "    return s.count('a')\n"
     ]
    }
   ],
   "source": [
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function named count_char which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Use UnsafeEvalProvider for simple examples; RestrictedEvalProvider may need extra globals.\n",
    "# DoctestHandler is not required for synthesis -- it is optional.\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a7b48",
   "metadata": {},
   "source": [
    "### Doctest Feedback\n",
    "\n",
    "You can optionally install a `DoctestHandler` to run doctests from the template docstring during callable synthesis.\n",
    "Without `DoctestHandler`, synthesis succeeds even if the docstring contains examples that don't match the synthesized function.\n",
    "With `DoctestHandler`, the doctests are executed and a `ResultDecodingError` is raised on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "793b12a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without DoctestHandler: synthesis succeeded (doctest not checked)\n",
      "  count_a('banana') = 3\n"
     ]
    }
   ],
   "source": [
    "from effectful.handlers.llm.completions import ResultDecodingError\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def count_char_with_bad_doctest(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function named count_char that counts the occurrances of '{char}'.\n",
    "    Do not use any tools.\n",
    "\n",
    "    Examples:\n",
    "        >>> count_char(\"banana\")\n",
    "        999\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Without DoctestHandler: synthesis succeeds (doctest is NOT checked)\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char_with_bad_doctest(\"a\")\n",
    "    assert callable(count_a)\n",
    "    print(\"Without DoctestHandler: synthesis succeeded (doctest not checked)\")\n",
    "    print(f\"  count_a('banana') = {count_a('banana')}\")\n",
    "\n",
    "# With DoctestHandler: synthesis fails because the doctest expects 999 but gets 3\n",
    "try:\n",
    "    with handler(provider), handler(UnsafeEvalProvider()), handler(DoctestHandler()):\n",
    "        count_a = count_char_with_bad_doctest(\"a\")\n",
    "except ResultDecodingError as e:\n",
    "    print(\"With DoctestHandler: synthesis failed as expected\")\n",
    "    print(f\"  Error: {type(e).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the weather information:\n",
      "\n",
      "- **Chicago**: Cold\n",
      "- **New York**: Wet\n",
      "- **Barcelona**: Sunny\n",
      "\n",
      "I suggest Barcelona as the city with good weather, as it is sunny there.\n"
     ]
    }
   ],
   "source": [
    "@Tool.define\n",
    "def cities() -> list[str]:\n",
    "    \"\"\"Return a list of cities that can be passed to `weather`.\"\"\"\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Given a city name, return a description of the weather in that city.\"\"\"\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59584a54",
   "metadata": {},
   "source": [
    "## Image Inputs\n",
    "\n",
    "You can pass `PIL.Image.Image` values directly to templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89992702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqAMAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQAmgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\" alt=\"Example image\" width=\"320\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simple yellow smiley face with black eyes and a curved mouth, representing a happy expression.\n"
     ]
    }
   ],
   "source": [
    "image_base64 = (\n",
    "    \"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqA\"\n",
    "    \"MAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg\"\n",
    "    \"+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQA\"\n",
    "    \"mgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\"\n",
    ")\n",
    "image = Image.open(io.BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def describe_image(image: Image.Image) -> str:\n",
    "    \"\"\"Return a short description of the following image.\n",
    "    {image}\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Example image\" width=\"320\" />'\n",
    "        )\n",
    "    )\n",
    "    print(describe_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Lizard.\n",
      "Lizard who?\n",
      "Lizard who? \n",
      "Lizard you been looking for a new pet? Because I'm ready to be your scaly buddy!\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char_with_bad_doctest', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'unstable_service', 'fetch_data', 'give_rating_for_movie', 'write_chapter', 'judge_chapter', 'write_multi_chapter_story'])\n",
      "=== Story with moral ===\n",
      "\n",
      "\n",
      "When exploring new and unknown areas, it's important to be aware of your surroundings and potential dangers, so you can enjoy your adventure safely.\n",
      "\n",
      "=== Funny story ===\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Mr. Whiskers indeed ensured that the curious wanderlust of a cat kept the laughter and unexpected surprises alive in the quiet town of Whiskerville.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools.values()\n",
    "assert story_funny in write_story.tools.values()\n",
    "print(\"Sub-templates available to write_story:\", write_story.tools.keys())\n",
    "\n",
    "with handler(provider):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": [
    "## Retrying LLM Requests\n",
    "LLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls and can also surface tool/runtime errors as tool messages:\n",
    "\n",
    "- `num_retries`: Maximum number of retry attempts (default: 3)\n",
    "- `include_traceback`: When `True`, include traceback details in the error feedback (default: False)\n",
    "- `catch_tool_errors`: Exception type(s) to catch during tool execution (default: `Exception`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Service unavailable! Attempt 1/3. Please retry.\n",
      "Result: The unstable service call was successful on the second attempt, and the data fetched is:\n",
      "\n",
      "- 1\n",
      "- 2\n",
      "- 3 Retries: 3\n"
     ]
    }
   ],
   "source": [
    "call_count = 0\n",
    "REQUIRED_RETRIES = 3\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def unstable_service() -> str:\n",
    "    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if call_count < REQUIRED_RETRIES:\n",
    "        raise ConnectionError(\n",
    "            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n",
    "        )\n",
    "    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n",
    "\n",
    "\n",
    "@Template.define  # unstable_service auto-captured from lexical scope\n",
    "def fetch_data() -> str:\n",
    "    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        result = fetch_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler(num_retries=3)):\n",
    "    result = fetch_data()\n",
    "    print(f\"Result: {result}\", \"Retries:\", call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "## Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error decoding response: 1 validation error for Response\n",
      "value.score\n",
      "  score must be 1–5, got 9 [type=invalid_score, input_value=9, input_type=int]. Please provide a valid response and try again.\n",
      "Score: 5/5\n",
      "Explanation: Die Hard receives a score of 5 out of 5. It is widely acclaimed for its deft blend of intense action, engaging plot, and iconic performances, which have solidified its status as a classic in the action genre. Bruce Willis's portrayal of John McClane is both relatable and heroic, offering a character that resonates with audiences. The film's ability to maintain suspense and deliver memorable moments throughout, along with its cultural impact and influence on subsequent action movies, justifies the perfect score.\n"
     ]
    }
   ],
   "source": [
    "@pydantic.dataclasses.dataclass\n",
    "class Rating:\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "    @field_validator(\"score\")\n",
    "    @classmethod\n",
    "    def check_score(cls, v):\n",
    "        if v < 1 or v > 5:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_score\",\n",
    "                \"score must be 1–5, got {v}\",\n",
    "                {\"v\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"explanation\")\n",
    "    @classmethod\n",
    "    def check_explanation_contains_score(cls, v, info):\n",
    "        score = info.data.get(\"score\", None)\n",
    "        if score is not None and str(score) not in v:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_explanation\",\n",
    "                \"explanation must mention the score {score}, got '{explanation}'\",\n",
    "                {\"score\": score, \"explanation\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def give_rating_for_movie(movie_name: str) -> Rating:\n",
    "    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        rating = give_rating_for_movie(\"Die Hard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler(num_retries=3)):\n",
    "    rating = give_rating_for_movie(\"Die Hard\")\n",
    "    print(f\"Score: {rating.score}/5\")\n",
    "    print(f\"Explanation: {rating.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0632c",
   "metadata": {},
   "source": [
    "## Generating higher-order functions\n",
    "Finally, we can generate higher-order functions that can call templates as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d02bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char_with_bad_doctest', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'unstable_service', 'fetch_data', 'give_rating_for_movie', 'write_chapter', 'judge_chapter'])\n",
      "=== Story with moral ===\n",
      "def write_moral_story(topic: str) -> str:\n",
      "    story = \"\"\n",
      "    chapter_number = 1\n",
      "    chapter_name = f\"The Beginning of {topic}\"\n",
      "    \n",
      "    while True:\n",
      "        chapter = write_chapter(chapter_number, chapter_name)\n",
      "        story += chapter\n",
      "        \n",
      "        if not judge_chapter(story, chapter_number):\n",
      "            break\n",
      "        \n",
      "        chapter_number += 1\n",
      "        chapter_name = f\"Chapter {chapter_number} of {topic}\"\n",
      "    \n",
      "    # Add a moral at the end of the story\n",
      "    story += f\"\\nMoral of the story: {topic} teaches us an important lesson about life.\"\n",
      "    return story\n",
      "Once upon a time in an enchanted land, there was a peculiar valley where numbers roamed like mythical creatures. Among these numbers, the number 1 was often seen as the least significant, overshadowed by larger and more complex siblings like 7, 8, or 9. Despite his small size, Number 1 was ambitious and determined to prove his worth.\n",
      "\n",
      "Every morning, while other numbers would boast about their additions and multiplications, Number 1 would practice tirelessly, joining forces with other numbers to create bigger values. His tenacity was a source of amusement for others, who thought he could never achieve much on his own.\n",
      "\n",
      "One day, an elderly zero, known for her wisdom, approached Number 1. \"My dear,\" she said softly, \"I see a great future for you if only you believe in yourself. The world often forgets that even the greatest numbers are built from unity.\"\n",
      "\n",
      "Encouraged by her words, Number 1 took on the daring quest to seek the Great Calculator, a mystical device rumored to grant numbers the power to be whatever they wished. Through forests of division and mountains of subtraction, he traveled, never giving up despite the odds.\n",
      "\n",
      "Upon reaching the calculator, Number 1 was challenged to prove his worth. With courage and the belief imparted by the wise zero, he declared, \"I wish to become the foundation upon which greatness is built!\"\n",
      "\n",
      "To everyone's astonishment, the Great Calculator whirred into life. It awarded him the power to unite numbers, demonstrating his undeniable importance. In the days that followed, Number 1 became the cornerstone of all numbers.\n",
      "\n",
      "It was with his newfound status that 1 proved a simple yet profound truth: oneness—the unity of a single entity—paves the way for boundless possibilities. He no longer needed to compete in size or scale, for he had realized his true potential.\n",
      "\n",
      "And thus, the valley learned a valuable lesson: sometimes, the smallest voice can hold the greatest strength. The legacy of Number 1 taught others to look beyond size and recognize the power within.\n",
      "\n",
      "The moral of the story is that value lies not in size or quantity, but in the unity and connections we create.**Title: The Tale of Two**\n",
      "\n",
      "Once upon a time, in the vibrant land of Numerica, there lived a humble, yet essential number named 2. In Numerica, each number had its distinct role to play, and the harmony of the land depended on their cooperation.\n",
      "\n",
      "Number 2, though modest in appearance, was the backbone of relationships. It was natural, balanced, and often found itself in pairs, proudly proclaiming its capability to double anything it touched. Whether joining hands with 1 to form the couple 12 or standing proudly as 20, it carried its duty with unwavering grace.\n",
      "\n",
      "One sunny day, a great uproar engulfed the peaceful land. Zero, feeling worthless and overlooked, decided to disrupt the harmony among numbers. \"I'm tired of being seen as nothing,\" Zero declared. \"I shall stand in the middle of all, creating confusion!\"\n",
      "\n",
      "Panic rippled through Numerica as Zero interjected itself into equations, causing mathematical mayhem. In a moment of crisis, the other numbers turned to 2, whose sense of balance was legendary. The wise elders of Numerica asked 2 to resolve the chaos.\n",
      "\n",
      "Stepping forward, 2 approached Zero with understanding eyes. \"You have a place here, just as every number does,\" 2 consoled the unsettled Zero. \"You are the start and the end; infinite possibilities await when you team up with us.\"\n",
      "\n",
      "Zero, touched by 2's kindness, agreed to return to its place. Together, 2 and Zero created new possibilities: 20, 200, 2,000—a testament to harmony and cooperation. From that day, Zero embraced its potential with pride.\n",
      "\n",
      "The land of Numerica returned to its serene order, and 2 continued to exemplify the essence of pairing and balance. Time worked its way through Numerica, and just like a pair of glasses brings clarity and focus, the number 2 continued to serve as a reminder of the power of partnership and unity.\n",
      "\n",
      "And thus, the land thrived ever more, singing praises of the humble number 2, whose quiet strength and harmony kept everything at peace.\n",
      "\n",
      "**Moral:** Too often do we overlook the importance of partnerships and balance. It is through cooperation with others that true potential is realized.\n",
      "Moral of the story: a curious cat teaches us an important lesson about life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def write_chapter(chapter_number: int, chapter_name: str) -> str:\n",
    "    \"\"\"Write a short story about {chapter_number}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def judge_chapter(story_so_far: str, chapter_number: int) -> bool:\n",
    "    \"\"\"Decide if the new chapter is coherence with the story so far. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_multi_chapter_story(style: Literal[\"moral\", \"funny\"]) -> Callable[[str], str]:\n",
    "    \"\"\"Generate a function that writes a story in style: {style} about the given topic.\n",
    "\n",
    "    The program can use helper functions defined elsewhere (DO NOT REDEFINE THEM):\n",
    "    - write_chapter(chapter_number: int, chapter_name: str) -> str\n",
    "    - judge_chapter(story_so_far: str, chapter_number: int) -> bool\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "print(\"Sub-templates available to write_story:\", write_multi_chapter_story.tools.keys())\n",
    "\n",
    "with (\n",
    "    handler(RetryLLMHandler(num_retries=3)),\n",
    "    handler(provider),\n",
    "    handler(UnsafeEvalProvider()),\n",
    "):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    function_that_writes_story = write_multi_chapter_story(\"moral\")\n",
    "    print(inspect.getsource(function_that_writes_story))\n",
    "    print(function_that_writes_story(\"a curious cat\"))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
