{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7fda1b8",
   "metadata": {},
   "source": [
    "# LLM Interface\n",
    "The `effectful.handlers.llm` module provides a simplified LLM interface that uses algebraic effects for modularity. The module interface consists of:\n",
    "\n",
    "- A decorator `Template.define` which creates a prompt template from a callable. A template is an LLM-implemented function whose behavior is specified by a template string. When a template is called, an LLM is invoked to produce the specified behavior.\n",
    "- A decorator `Tool.define` which exposes Python callables as tools that templates can call. Tool signatures and docstrings define the schema passed to the model.\n",
    "- Structured output handling via `Encodable` (used internally by templates and tool calls) to serialize/deserialize Python types.\n",
    "- LLM providers such as `LiteLLMProvider`, and reliability helpers like `RetryLLMHandler` and `ReplayLiteLLMProvider`, which can be composed with `handler(...)` to control execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaf649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import dataclasses\n",
    "import functools\n",
    "import io\n",
    "from typing import Literal\n",
    "\n",
    "import litellm\n",
    "import pydantic\n",
    "from IPython.display import HTML, display\n",
    "from litellm.caching.caching import Cache\n",
    "from PIL import Image\n",
    "from pydantic import field_validator\n",
    "from pydantic_core import PydanticCustomError\n",
    "\n",
    "from effectful.handlers.llm import Template, Tool\n",
    "from effectful.handlers.llm.completions import (\n",
    "    LiteLLMProvider,\n",
    "    RetryLLMHandler,\n",
    ")\n",
    "from effectful.ops.semantics import NotHandled, handler\n",
    "\n",
    "provider = LiteLLMProvider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093243e0",
   "metadata": {},
   "source": [
    "In the following sections, we walk through each of the mentioned components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c639d3",
   "metadata": {},
   "source": [
    "## Prompt Templates\n",
    "\n",
    "This template function writes (bad) poetry on a given theme. While difficult to implement in Python, an LLM can provide a reasonable implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e832675",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def limerick(theme: str) -> str:\n",
    "    \"\"\"Write a limerick on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca6919",
   "metadata": {},
   "source": [
    "If we call the template with a provider interpretation installed, we get reasonable behavior. The LLM is nondeterministic by default, so calling the template twice with the same arguments gives us different results.\n",
    "\n",
    "Templates are regular callables, so can be converted to operations with `defop` if we want to override the LLM implementation in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634f6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the sea where the shimmering fish \n",
      "Dance around like a silvery wish,\n",
      "They wiggle and glide,\n",
      "With the tide, side by side,\n",
      "Turning waves into their swirlish dish.\n",
      "----------------------------------------\n",
      "There once was a fish named Blue,\n",
      "Who swam in a sea of bright hue.\n",
      "With scales shining bright,\n",
      "He'd dance in the light,\n",
      "And none were as charming as Blue.\n"
     ]
    }
   ],
   "source": [
    "with handler(provider):\n",
    "    print(limerick(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(limerick(\"fish\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59acbc",
   "metadata": {},
   "source": [
    "If we want deterministic behavior, we can cache the template call. We can either cache it with the default `@functools.cache` or use LiteLLM's built-in cache by setting a cache backend and passing `caching=True` to the provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706ce53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Silent stream below,\n",
      "Gleaming scales in dancing waves—\n",
      "Fish glide through cool dreams.\n",
      "----------------------------------------\n",
      "Silent stream below,\n",
      "Gleaming scales in dancing waves—\n",
      "Fish glide through cool dreams.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyendat/Marc/effectful/.venv/lib/python3.12/site-packages/pydantic/main.py:528: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected 10 fields but got 6: Expected `Message` - serialized value may not be as expected [field_name='message', input_value=Message(content='{\"value\"...: None}, annotations=[]), input_type=Message])\n",
      "  PydanticSerializationUnexpectedValue(Expected `StreamingChoices` - serialized value may not be as expected [field_name='choices', input_value=Choices(finish_reason='st...ider_specific_fields={}), input_type=Choices])\n",
      "  return self.__pydantic_serializer__.to_json(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In streams not too deep,  \n",
      "Silver swimmers glide below,  \n",
      "Silent fins whisper.\n",
      "----------------------------------------\n",
      "Silvery fish dart,\n",
      "Through the gentle stream they glide—\n",
      "Nature's dance unfolds.\n",
      "\n",
      "Fish beneath the waves,\n",
      "Silent currents in their dance—\n",
      "Nature's quiet grace.\n",
      "----------------------------------------\n",
      "In the whispering stream,\n",
      "silver scales dance and shimmer—\n",
      "a fleeting shadow.\n"
     ]
    }
   ],
   "source": [
    "@functools.cache\n",
    "@Template.define\n",
    "def haiku(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def haiku_no_cache(theme: str) -> str:\n",
    "    \"\"\"Write a haiku on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku(\"fish\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku(\"fish\"))\n",
    "\n",
    "print()\n",
    "# Enable LiteLLM caching by setting a cache backend and enabling caching.\n",
    "litellm.cache = Cache()\n",
    "provider_cached = LiteLLMProvider(caching=True)\n",
    "try:\n",
    "    with handler(provider_cached):\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "        print(\"-\" * 40)\n",
    "        print(haiku_no_cache(\"fish2\"))\n",
    "finally:\n",
    "    litellm.cache = None\n",
    "\n",
    "print()\n",
    "with handler(provider):\n",
    "    print(haiku_no_cache(\"fish3\"))\n",
    "    print(\"-\" * 40)\n",
    "    print(haiku_no_cache(\"fish3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13adb300",
   "metadata": {},
   "source": [
    "## Converting LLM Results to Python Objects\n",
    "\n",
    "Type conversion is handled by `decode`. By default, primitive types are converted. `DecodeError` is raised if a response cannot be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c766859",
   "metadata": {},
   "outputs": [],
   "source": [
    "@Template.define\n",
    "def primes(first_digit: int) -> int:\n",
    "    \"\"\"Give a prime number with {first_digit} as the first digit. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    assert type(primes(6)) is int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d78a71",
   "metadata": {},
   "source": [
    "More complex types can be converted by providing handlers for `decode`. Callable synthesis is supported via `Encodable` and the evaluation providers in `effectful.handlers.llm.evaluation` (`UnsafeEvalProvider` or `RestrictedEvalProvider`), which enable parsing/compiling/executing synthesized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c83bbdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def count_a(s: str) -> int:\n",
      "    return s.count('a')\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from collections.abc import Callable\n",
    "\n",
    "from effectful.handlers.llm.evaluation import UnsafeEvalProvider\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def count_char(char: str) -> Callable[[str], int]:\n",
    "    \"\"\"Write a function which takes a string and counts the occurrances of '{char}'. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Use UnsafeEvalProvider for simple examples; RestrictedEvalProvider may need extra globals.\n",
    "with handler(provider), handler(UnsafeEvalProvider()):\n",
    "    count_a = count_char(\"a\")\n",
    "    assert callable(count_a)\n",
    "    assert count_a(\"banana\") == 3\n",
    "    assert count_a(\"cherry\") == 0\n",
    "    # Print the source code of the generated function\n",
    "    print(inspect.getsource(count_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ee445",
   "metadata": {},
   "source": [
    "## Tool Calling\n",
    "\n",
    "`Operation`s defined in the lexical scope of a `Template` are automatically available for the LLM to call as tools. The description of these operations is inferred from their type annotations and docstrings.\n",
    "\n",
    "Tool calls are mediated by a helper operation `tool_call`. Handling this operation allows tool use to be tracked or logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66711301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the weather descriptions:\n",
      "- **Chicago**: Cold\n",
      "- **New York**: Wet\n",
      "- **Barcelona**: Sunny\n",
      "\n",
      "I suggest Barcelona since it has sunny weather, which is generally considered good for most people.\n"
     ]
    }
   ],
   "source": [
    "@Tool.define\n",
    "def cities() -> list[str]:\n",
    "    \"\"\"Return a list of cities that can be passed to `weather`.\"\"\"\n",
    "    return [\"Chicago\", \"New York\", \"Barcelona\"]\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def weather(city: str) -> str:\n",
    "    \"\"\"Given a city name, return a description of the weather in that city.\"\"\"\n",
    "    status = {\"Chicago\": \"cold\", \"New York\": \"wet\", \"Barcelona\": \"sunny\"}\n",
    "    return status.get(city, \"unknown\")\n",
    "\n",
    "\n",
    "@Template.define  # cities and weather auto-captured from lexical scope\n",
    "def vacation() -> str:\n",
    "    \"\"\"Use the provided tools to suggest a city that has good weather. Use only the `cities` and `weather` tools provided.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    print(vacation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59584a54",
   "metadata": {},
   "source": [
    "## Image Inputs\n",
    "\n",
    "You can pass `PIL.Image.Image` values directly to templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89992702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqAMAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQAmgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\" alt=\"Example image\" width=\"320\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an image of a simple yellow smiley face with black eyes and a smile on a yellow background.\n"
     ]
    }
   ],
   "source": [
    "image_base64 = (\n",
    "    \"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAhElEQVR4nO2W4QqA\"\n",
    "    \"MAiEVXr/VzYWDGoMdk7Cgrt/sUs/DqZTd3EplFU2JwATYAJMoOlAB4bq89s95+Mg\"\n",
    "    \"+gyAchsKAYplBBBA43hFhfxnUixDjdEUUL8hpr7R0KLdt9qElzcyiu8As+Kr8zQA\"\n",
    "    \"mgLavAl+kIzFZyCRxtsAmWb/voZvqRzgBE1sIDuVFX4eAAAAAElFTkSuQmCC\"\n",
    ")\n",
    "image = Image.open(io.BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def describe_image(image: Image.Image) -> str:\n",
    "    \"\"\"Return a short description of the following image.\n",
    "    {image}\n",
    "    \"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<img src=\"data:image/png;base64,{image_base64}\" alt=\"Example image\" width=\"320\" />'\n",
    "        )\n",
    "    )\n",
    "    print(describe_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d221feb",
   "metadata": {},
   "source": [
    "## Structured Output Generation\n",
    "\n",
    "Constrained generation is used for any type that is convertible to a Pydantic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17668ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> You are onstage at a comedy club. You tell the following joke:\n",
      "Knock knock.\n",
      "Who's there?\n",
      "Lizard.\n",
      "Lizard who?\n",
      "Lizard who? Lizard be a joke if I wasn't at your door!\n",
      "> The crowd laughs politely.\n"
     ]
    }
   ],
   "source": [
    "@dataclasses.dataclass\n",
    "class KnockKnockJoke:\n",
    "    whos_there: str\n",
    "    punchline: str\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def write_joke(theme: str) -> KnockKnockJoke:\n",
    "    \"\"\"Write a knock-knock joke on the theme of {theme}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def rate_joke(joke: KnockKnockJoke) -> bool:\n",
    "    \"\"\"Decide if {joke} is funny or not. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "def do_comedy():\n",
    "    joke = write_joke(\"lizards\")\n",
    "    print(\"> You are onstage at a comedy club. You tell the following joke:\")\n",
    "    print(\n",
    "        f\"Knock knock.\\nWho's there?\\n{joke.whos_there}.\\n{joke.whos_there} who?\\n{joke.punchline}\"\n",
    "    )\n",
    "    if rate_joke(joke):\n",
    "        print(\"> The crowd laughs politely.\")\n",
    "    else:\n",
    "        print(\"> The crowd stares in stony silence.\")\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    do_comedy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0003944",
   "metadata": {},
   "source": [
    "## Template Composition\n",
    "\n",
    "Templates defined in the lexical scope are also captured, enabling template composition. One template can use the result of another template in a pipeline:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78a4bf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny'])\n",
      "=== Story with moral ===\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "=== Funny story ===\n",
      "\n",
      "\n",
      "And so, Whiskers the curious cat continued to slink through life, tail high, always ready for another amusing escapade.\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def story_with_moral(topic: str) -> str:\n",
    "    \"\"\"Write a short story about {topic} and end with a moral lesson. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def story_funny(topic: str) -> str:\n",
    "    \"\"\"Write a funny, humorous story about {topic}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_story(topic: str, style: str) -> str:\n",
    "    \"\"\"Write a story about {topic} in the style: {style}.\n",
    "    Available styles: 'moral' for a story with a lesson, 'funny' for humor. Use story_funny for humor, story_with_moral for a story with a lesson.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "assert story_with_moral in write_story.tools.values()\n",
    "assert story_funny in write_story.tools.values()\n",
    "print(\"Sub-templates available to write_story:\", write_story.tools.keys())\n",
    "\n",
    "with handler(provider):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    print(write_story(\"a curious cat\", \"moral\"))\n",
    "    print()\n",
    "    print(\"=== Funny story ===\")\n",
    "    print(write_story(\"a curious cat\", \"funny\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25826d",
   "metadata": {},
   "source": [
    "## Retrying LLM Requests\n",
    "LLM calls can sometimes fail due to transient errors or produce invalid outputs. The `RetryLLMHandler` automatically retries failed template calls and can also surface tool/runtime errors as tool messages:\n",
    "\n",
    "- `include_traceback`: When `True`, include traceback details in the error feedback (default: True)\n",
    "- `catch_tool_errors`: Exception type(s) to catch during tool execution (default: `Exception`)\n",
    "- `**kwargs`: Additional keyword arguments forwarded to `tenacity.Retrying` (defaults: `stop=stop_after_attempt(4)`, `wait=wait_none()`, `reraise=True`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc0a96",
   "metadata": {},
   "source": [
    "Example usage: having an unstable service that seldomly fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4334d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Tool execution failed: Error executing tool 'unstable_service': Service unavailable! Attempt 1/3. Please retry.\n",
      "Result: The unstable service successfully returned the following data: `[1, 2, 3]`. Retries: 3\n"
     ]
    }
   ],
   "source": [
    "call_count = 0\n",
    "REQUIRED_RETRIES = 3\n",
    "\n",
    "\n",
    "@Tool.define\n",
    "def unstable_service() -> str:\n",
    "    \"\"\"Fetch data from an unstable external service. May require retries.\"\"\"\n",
    "    global call_count\n",
    "    call_count += 1\n",
    "    if call_count < REQUIRED_RETRIES:\n",
    "        raise ConnectionError(\n",
    "            f\"Service unavailable! Attempt {call_count}/{REQUIRED_RETRIES}. Please retry.\"\n",
    "        )\n",
    "    return \"{ 'status': 'ok', 'data': [1, 2, 3] }\"\n",
    "\n",
    "\n",
    "@Template.define  # unstable_service auto-captured from lexical scope\n",
    "def fetch_data() -> str:\n",
    "    \"\"\"Use the unstable_service tool to fetch data.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        result = fetch_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler()):\n",
    "    result = fetch_data()\n",
    "    print(f\"Result: {result}\", \"Retries:\", call_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac00e01",
   "metadata": {},
   "source": [
    "## Retrying with Validation Errors\n",
    "As noted above, the `RetryHandler` can also be used to retry on runtime/validation error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b2b225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Error decoding response: 1 validation error for Response\n",
      "value.score\n",
      "  score must be 1–5, got 9 [type=invalid_score, input_value=9, input_type=int]. Please provide a valid response and try again.\n",
      "Score: 5/5\n",
      "Explanation: Die Hard is a quintessential action film that has deeply influenced the genre. Its engaging storyline, memorable characters, and groundbreaking action scenes have made it a beloved classic. The film's humor and suspense balance combined with Bruce Willis' iconic performance contribute to its enduring appeal. It rightfully earns a top score of 5 out of 5 for its impact and entertainment value.\n"
     ]
    }
   ],
   "source": [
    "@pydantic.dataclasses.dataclass\n",
    "class Rating:\n",
    "    score: int\n",
    "    explanation: str\n",
    "\n",
    "    @field_validator(\"score\")\n",
    "    @classmethod\n",
    "    def check_score(cls, v):\n",
    "        if v < 1 or v > 5:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_score\",\n",
    "                \"score must be 1–5, got {v}\",\n",
    "                {\"v\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "    @field_validator(\"explanation\")\n",
    "    @classmethod\n",
    "    def check_explanation_contains_score(cls, v, info):\n",
    "        score = info.data.get(\"score\", None)\n",
    "        if score is not None and str(score) not in v:\n",
    "            raise PydanticCustomError(\n",
    "                \"invalid_explanation\",\n",
    "                \"explanation must mention the score {score}, got '{explanation}'\",\n",
    "                {\"score\": score, \"explanation\": v},\n",
    "            )\n",
    "        return v\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def give_rating_for_movie(movie_name: str) -> Rating:\n",
    "    \"\"\"Give a rating for {movie_name}. The explanation MUST include the numeric score. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "with handler(provider):\n",
    "    try:\n",
    "        rating = give_rating_for_movie(\"Die Hard\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "with handler(provider), handler(RetryLLMHandler()):\n",
    "    rating = give_rating_for_movie(\"Die Hard\")\n",
    "    print(f\"Score: {rating.score}/5\")\n",
    "    print(f\"Explanation: {rating.explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec0632c",
   "metadata": {},
   "source": [
    "## Generating higher-order functions\n",
    "Finally, we can generate higher-order functions that can call templates as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d02bc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sub-templates available to write_story: dict_keys(['limerick', 'haiku_no_cache', 'primes', 'count_char', 'cities', 'weather', 'vacation', 'describe_image', 'write_joke', 'rate_joke', 'story_with_moral', 'story_funny', 'write_story', 'unstable_service', 'fetch_data', 'give_rating_for_movie', 'write_chapter', 'judge_chapter'])\n",
      "=== Story with moral ===\n",
      "def generate_moral_story(topic: str) -> str:\n",
      "    story_so_far = \"\"\n",
      "    chapter_number = 1\n",
      "    chapter_name_prefix = \"Chapter\"\n",
      "    \n",
      "    while True:\n",
      "        try:\n",
      "            chapter_name = f\"{chapter_name_prefix} {chapter_number}\"\n",
      "            chapter = write_chapter(chapter_number, chapter_name)\n",
      "            if judge_chapter(story_so_far, chapter_number):\n",
      "                story_so_far += chapter + \"\\n\"\n",
      "                chapter_number += 1\n",
      "                \n",
      "                # For the purpose of the demonstration, let's stop after 3 chapters\n",
      "                if chapter_number > 3:\n",
      "                    break\n",
      "            else:\n",
      "                # If the chapter isn't coherent, we might revise it or try a different topic.\n",
      "                chapter_number += 1\n",
      "                continue\n",
      "        except Exception as e:\n",
      "            # Handle exception by logging or showing a message, then continue\n",
      "            print(f\"An error occurred: {e}. Trying again.\")\n",
      "            continue            \n",
      "\n",
      "    return story_so_far\n",
      "Once upon a time, in the quaint town of Arithmetville, there was a number named Four. Four lived a simple life in the Number Kingdom where each digit was celebrated for its unique role. The citizens, ranging from One to Nine, all had their special talents, but Four often felt overshadowed by the glamour of Seven or the strength of Nine.\n",
      "\n",
      "Four was neat and symmetrical, embodying balance and order. However, despite its perfect symmetry, Four struggled with feelings of inadequacy. \"I'm just ordinary,\" Four would sigh, watching Three, the number of harmony and growth, excel in social gatherings with its effortless charisma.\n",
      "\n",
      "One bright and sunny day, a problem arose in the Number Kingdom when Number Madness—a chaotic jumble that scrambled numbers out of order—descended upon the kingdom. The great leader Ten gathered all the digits to find a solution.\n",
      "\n",
      "\"We need someone who can provide stability and order to defeat Number Madness,\" Ten declared.\n",
      "\n",
      "Six said it was too curvy, and Eight, though powerful, said it was often mistaken for infinity and couldn't help. But the wise old Zero whispered, \"What about Four?\"\n",
      "\n",
      "Hesitant but hopeful, Four stepped forward. Armed with knowledge of perfect divisions and its role in creating stability, Four devised a plan. Using its even nature, Four aligned the numbers perfectly, counteracting the chaos with its impeccable sense of balance. Number Madness was soon vanquished.\n",
      "\n",
      "The kingdom cheered, and even Seven and Nine applauded Four. For the first time, Four felt proud, realizing that everyone, including itself, played an integral role in the grand equation of life.\n",
      "\n",
      "From that day forward, Four embraced its identity and continued to be the sturdy backbone of stability in the Number Kingdom. And so, the simple truth was revealed: It's in the everyday skill of balancing that greatness is found.\n",
      "\n",
      "**Moral of the story:** Embrace who you are, for every role is vital, and true advantage often lies in what makes you different.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sub-templates for different story styles\n",
    "@Template.define\n",
    "def write_chapter(chapter_number: int, chapter_name: str) -> str:\n",
    "    \"\"\"Write a short story about {chapter_number}. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "@Template.define\n",
    "def judge_chapter(story_so_far: str, chapter_number: int) -> bool:\n",
    "    \"\"\"Decide if the new chapter is coherence with the story so far. Do not use any tools.\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Main orchestrator template - has access to sub-templates\n",
    "@Template.define\n",
    "def write_multi_chapter_story(style: Literal[\"moral\", \"funny\"]) -> Callable[[str], str]:\n",
    "    \"\"\"Generate a function that writes a story in style: {style} about the given topic.\n",
    "\n",
    "    If you raise exception, handle it yourself.\n",
    "    The program can use helper functions defined elsewhere (DO NOT REDEFINE THEM):\n",
    "    - write_chapter(chapter_number: int, chapter_name: str) -> str\n",
    "    - judge_chapter(story_so_far: str, chapter_number: int) -> bool\"\"\"\n",
    "    raise NotHandled\n",
    "\n",
    "\n",
    "# Verify sub-templates are captured in write_story's lexical context\n",
    "print(\"Sub-templates available to write_story:\", write_multi_chapter_story.tools.keys())\n",
    "\n",
    "with (\n",
    "    handler(RetryLLMHandler()),\n",
    "    handler(provider),\n",
    "    handler(UnsafeEvalProvider()),\n",
    "):\n",
    "    print(\"=== Story with moral ===\")\n",
    "    function_that_writes_story = write_multi_chapter_story(\"moral\")\n",
    "    print(inspect.getsource(function_that_writes_story))\n",
    "    print(function_that_writes_story(\"a curious cat\"))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
