{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named tensor notation with funsors (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**This is a translation of the [Named Tensor Notation (Chiang, Rush, Barak 2021)](https://namedtensor.github.io/) example from the [funsor](https://funsor.pyro.ai/) library to `effectful`. Much of the expository text is taken directly from the original.**\n",
    "\n",
    "The mathematical notation with *named axes* introduced in [Named Tensor Notation (Chiang, Rush, Barak 2021)](https://namedtensor.github.io/) improves the readability of mathematical formulas involving multidimensional arrays. This includes tensor operations such as elementwise operations, reductions, contractions, renaming, indexing, and broadcasting. Part 1 covers examples from [2 Informal Overview](https://namedtensor.github.io/#sec:overview), [3.4.2 Advanced Indexing](https://namedtensor.github.io/#sec:examples), and [5 Formal Definitions](https://namedtensor.github.io/#sec:definitions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import torch\n",
    "from torch import tensor\n",
    "\n",
    "from effectful.ops.core import evaluate\n",
    "from effectful.ops.handler import handler\n",
    "from effectful.internals.sugar import gensym, torch_getitem\n",
    "from effectful.indexed.ops import Indexable, to_tensor\n",
    "\n",
    "\n",
    "def subst(term, substs):\n",
    "    with handler(\n",
    "        {k: functools.partial(lambda vv: vv, v) for (k, v) in substs.items()},\n",
    "    ):\n",
    "        return evaluate(term)\n",
    "\n",
    "\n",
    "def reduce(indexes, indexed_tensor, reducer):\n",
    "    \"\"\"Reduce an indexed tensor along one or more named dimensions.\n",
    "\n",
    "    Args:\n",
    "    - indexes: Names of dimensions to reduce.\n",
    "    - indexed_tensor: The tensor to reduce.\n",
    "    - reducer: A reduction function like `torch.sum`. Must take `tensor`, `dim`, and `keepdim` arguments.\n",
    "\n",
    "    Returns: A new indexed tensor with the specified dimensions reduced.\n",
    "\n",
    "    Example:\n",
    "    >>> width, height = gensym(int, name='width'), gensym(int, name='height')\n",
    "    >>> t = indexed(torch.ones(2, 3))[width(), height()]\n",
    "    >>> reduce([width], t, \"sum\")\n",
    "    indexed(tensor([2., 2., 2.]))[height()]\n",
    "    \"\"\"\n",
    "    num_positional = len(indexed_tensor.shape)\n",
    "    # convert indexed dimensions to positional and flatten all new positional dims\n",
    "    t = to_tensor(indexed_tensor, indexes)\n",
    "    new_positional = len(t.shape) - num_positional\n",
    "    t_flat = torch.flatten(t, 0, new_positional - 1)\n",
    "\n",
    "    # reduce dim 0 into the first index of dim 0, then return reduction\n",
    "    return reducer(t_flat, 0, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tensor axis is given a name:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "  A &\\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}height}[3] \\times \\mathsf{\\vphantom{fg}width}[3]} = \\mathbb{R}^{\\mathsf{\\vphantom{fg}width}[3] \\times \\mathsf{\\vphantom{fg}height}[3]} \\\\\n",
    "  A &= \\mathsf{\\vphantom{fg}height}\n",
    "  \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "    3 & 1 & 4 \\\\\n",
    "    1 & 5 & 9 \\\\\n",
    "    2 & 6 & 5\n",
    "  \\end{bmatrix}\\end{array} =\n",
    "  \\mathsf{\\vphantom{fg}width}\n",
    "  \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}height}\\\\\\begin{bmatrix}\n",
    "    3 & 1 & 2 \\\\\n",
    "    1 & 5 & 6 \\\\\n",
    "    4 & 9 & 5\n",
    "  \\end{bmatrix}\\end{array}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[3, 1, 4],\n",
       "                  [1, 5, 9],\n",
       "                  [2, 6, 5]]))[height(), width()]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height, width = gensym(int, name=\"height\"), gensym(int, name=\"width\")\n",
    "t = tensor([[3, 1, 4], [1, 5, 9], [2, 6, 5]])\n",
    "A = Indexable(tensor([[3, 1, 4], [1, 5, 9], [2, 6, 5]]))[height(), width()]\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access elements of $A$ using named indices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{\\mathsf{\\vphantom{fg}height}(1), \\mathsf{\\vphantom{fg}width}(3)} = A_{\\mathsf{\\vphantom{fg}width}(3), \\mathsf{\\vphantom{fg}height}(1)} = 4\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subst(A, {height: 0, width: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial indexing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "A_{\\mathsf{\\vphantom{fg}height}(1)} &= \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\n",
    "\\begin{bmatrix}\n",
    "  3 & 1 & 4\n",
    "\\end{bmatrix}\\end{array}\n",
    "&\n",
    "A_{\\mathsf{\\vphantom{fg}width}(3)} &= \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}height}\\\\\n",
    "\\begin{bmatrix}\n",
    "  4 & 9 & 5\n",
    "\\end{bmatrix}\\end{array}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([3, 1, 4]))[width()]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subst(A, {height: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([4, 9, 5]))[height()]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subst(A, {width: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise operations and broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementwise operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac1{1+\\exp(-A)} = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\n",
    "\\begin{bmatrix}\n",
    "  \\frac 1{1+\\exp(-3)} & \\frac 1{1+\\exp(-1)} & \\frac 1{1+\\exp(-4)} \\\\[1ex]\n",
    "  \\frac 1{1+\\exp(-1)} & \\frac 1{1+\\exp(-5)} & \\frac 1{1+\\exp(-9)} \\\\[1ex]\n",
    "  \\frac 1{1+\\exp(-2)} & \\frac 1{1+\\exp(-6)} & \\frac 1{1+\\exp(-5)}\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[0.9526, 0.7311, 0.9820],\n",
       "                  [0.7311, 0.9933, 0.9999],\n",
       "                  [0.8808, 0.9975, 0.9933]]))[height(), width()]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (1 + (-A).exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors with different shapes are automatically broadcasted against each other before an operation is applied. Let"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "  x &\\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}height}[3]} & y &\\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}width}[3]} \\\\\n",
    "  x &= \\mathsf{\\vphantom{fg}height}\n",
    "  \\begin{array}[b]{@{}c@{}}\\\\\n",
    "  \\begin{bmatrix}\n",
    "    2 \\\\ 7 \\\\ 1\n",
    "  \\end{bmatrix}\\end{array} & \n",
    "  y &= \n",
    "  \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "    1 & 4 & 1\n",
    "  \\end{bmatrix}\\end{array}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Indexable(tensor([2, 7, 1]))[height()]\n",
    "y = Indexable(tensor([1, 4, 1]))[width()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary addition operation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "A + x &= \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "  3+2 & 1+2 & 4+2 \\\\\n",
    "  1+7 & 5+7 & 9+7 \\\\\n",
    "  2+1 & 6+1 & 5+1\n",
    "\\end{bmatrix}\\end{array} &\n",
    "A + y &= \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "  3+1 & 1+4 & 4+1 \\\\\n",
    "  1+1 & 5+4 & 9+1 \\\\\n",
    "  2+1 & 6+4 & 5+1\n",
    "\\end{bmatrix}\\end{array}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[ 5,  3,  6],\n",
       "                  [ 8, 12, 16],\n",
       "                  [ 3,  7,  6]]))[height(), width()]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[ 4,  5,  5],\n",
       "                  [ 2,  9, 10],\n",
       "                  [ 3, 10,  6]]))[height(), width()]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary multiplication operation:\n",
    "\n",
    "$$\n",
    "A \\odot x = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "  3\\cdot2 & 1\\cdot2 & 4\\cdot2 \\\\\n",
    "  1\\cdot7 & 5\\cdot7 & 9\\cdot7 \\\\\n",
    "  2\\cdot1 & 6\\cdot1 & 5\\cdot1\n",
    "\\end{bmatrix}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[ 6,  2,  8],\n",
       "                  [ 7, 35, 63],\n",
       "                  [ 2,  6,  5]]))[height(), width()]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary maximum operation:\n",
    "\n",
    "$$\n",
    "\\max(A, y) = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\\begin{bmatrix}\n",
    "  \\max(3, 1) & \\max(1, 4) & \\max(4, 1) \\\\\n",
    "  \\max(1, 1) & \\max(5, 4) & \\max(9, 1) \\\\\n",
    "  \\max(2, 1) & \\max(6, 4) & \\max(5, 1)\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[3, 4, 4],\n",
       "                  [1, 5, 9],\n",
       "                  [2, 6, 5]]))[height(), width()]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(A, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named axes can be reduced over by calling the `.reduce` method and specifying the [reduction operator](https://en.wikipedia.org/wiki/Reduction_Operator) and names of reduced axes. Note that reduction is defined only for operators that are associative and commutative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum\\limits_{\\substack{\\mathsf{\\vphantom{fg}height}}} A = \\sum_i A_{\\mathsf{\\vphantom{fg}height}(i)} = \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\n",
    "\\begin{bmatrix}\n",
    "  3+1+2 & 1+5+6 & 4+9+5\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([ 6, 12, 18]))[width()]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height], A, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum\\limits_{\\substack{\\mathsf{\\vphantom{fg}width}}} A = \\sum_j A_{\\mathsf{\\vphantom{fg}width}(j)} = \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}height}\\\\\n",
    "\\begin{bmatrix}\n",
    "  3+1+4 & 1+5+9 & 2+6+5\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([ 8, 15, 13]))[height()]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([width], A, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduction over multiple axes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum\\limits_{\\substack{\\mathsf{\\vphantom{fg}height}\\\\\n",
    " \\mathsf{\\vphantom{fg}width}}} A = \\sum_i \\sum_j A_{\\mathsf{\\vphantom{fg}height}(i),\\mathsf{\\vphantom{fg}width}(j)} = 3+1+4+1+5+9+2+6+5.\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height, width], A, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\prod\\limits_{\\substack{\\mathsf{\\vphantom{fg}height}}} A = \\prod_i A_{\\mathsf{\\vphantom{fg}height}(i)} = \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\n",
    "\\begin{bmatrix}\n",
    "  3\\cdot1\\cdot2 & 1\\cdot5\\cdot6 & 4\\cdot9\\cdot5\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([  6,  30, 180]))[width()]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height], A, torch.prod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Max reduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\max\\limits_{\\substack{\\mathsf{\\vphantom{fg}height}}} A = \\max \\{A_{\\mathsf{\\vphantom{fg}height}(i)} \\mid 1 \\leq i \\leq n\\} = \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\\\\\n",
    "\\begin{bmatrix}\n",
    "  \\max(3, 1, 2) & \\max(1, 5, 6) & \\max(4, 9, 5)\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([3, 6, 9]))[width()]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height], A, torch.amax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contraction operation can be written as elementwise multiplication followed by summation over an axis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A \\mathbin{\\underset{\\substack{\\mathsf{\\vphantom{fg}width}}}{\\vphantom{fg}\\odot}} y = \\sum_j A_{\\mathsf{\\vphantom{fg}width}(j)} \\, y_{\\mathsf{\\vphantom{fg}width}(j)} = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\\\\\begin{bmatrix}\n",
    "  3\\cdot 1 + 1\\cdot 4 + 4\\cdot 1 \\\\\n",
    "  1\\cdot 1 + 5\\cdot 4 + 9\\cdot 1 \\\\\n",
    "  2\\cdot 1 + 6\\cdot 4 + 5\\cdot 1\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([11, 30, 31]))[height()]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([width], A * y, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other operations from linear algebra:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x \\mathbin{\\underset{\\substack{\\mathsf{\\vphantom{fg}height}}}{\\vphantom{fg}\\odot}} x = \\sum_i x_{\\mathsf{\\vphantom{fg}height}(i)} \\, x_{\\mathsf{\\vphantom{fg}height}(i)} \\qquad \\text{inner product}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(54)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height], x * x, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "[x \\odot y]_{\\mathsf{\\vphantom{fg}height}(i), \\mathsf{\\vphantom{fg}width}(j)} = x_{\\mathsf{\\vphantom{fg}height}(i)} \\, y_{\\mathsf{\\vphantom{fg}width}(j)} \\qquad \\text{outer product}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[ 2,  8,  2],\n",
       "                  [ 7, 28,  7],\n",
       "                  [ 1,  4,  1]]))[height(), width()]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A \\mathbin{\\underset{\\substack{\\mathsf{\\vphantom{fg}width}}}{\\vphantom{fg}\\odot}} y = \\sum_i A_{\\mathsf{\\vphantom{fg}width}(i)} \\, y_{\\mathsf{\\vphantom{fg}width}(i)} \\qquad \\text{matrix-vector product}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([11, 30, 31]))[height()]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([width], A * y, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x \\mathbin{\\underset{\\substack{\\mathsf{\\vphantom{fg}height}}}{\\vphantom{fg}\\odot}} A = \\sum_i x_{\\mathsf{\\vphantom{fg}height}(i)} \\, A_{\\mathsf{\\vphantom{fg}height}(i)} \\qquad \\text{vector-matrix product} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([15, 43, 76]))[width()]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([height], x * A, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A \\mathbin{\\underset{\\substack{\\mathsf{\\vphantom{fg}width}}}{\\vphantom{fg}\\odot}} B = \\sum_i A_{\\mathsf{\\vphantom{fg}width}(i)} \\odot B_{\\mathsf{\\vphantom{fg}width}(i)} \\qquad \\text{matrix-matrix product}~(B \\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}width}\\times \\mathsf{\\vphantom{fg}width2}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[ 46,  22,  39],\n",
       "                  [100,  49,  59],\n",
       "                  [ 76,  43,  40]]))[height(), width2()]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width2 = gensym(int, name=\"width2\")\n",
    "B = Indexable(\n",
    "    tensor([[3, 2, 5], [5, 4, 0], [8, 3, 6]]),\n",
    ")[width(), width2()]\n",
    "\n",
    "reduce([width], A * B, torch.sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contraction can be generalized to other binary and reduction operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\max_{\\mathsf{\\vphantom{fg}width}} (A + y) = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\\\\\begin{bmatrix}\n",
    "  \\max(3+1, 1+4, 4+1) \\\\\n",
    "  \\max(1+1, 5+4, 9+1) \\\\\n",
    "  \\max(2+1, 6+4, 5+1)\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([ 5, 10, 10]))[height()]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce([width], A + y, torch.amax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming and reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming funsors is simple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{\\mathsf{\\vphantom{fg}height}\\rightarrow\\mathsf{\\vphantom{fg}height2}} = \\mathsf{\\vphantom{fg}height2}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\n",
    "\\\\\\begin{bmatrix}\n",
    "  3 & 1 & 4 \\\\\n",
    "  1 & 5 & 9 \\\\\n",
    "  2 & 6 & 5 \\\\\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[3, 1, 4],\n",
       "                  [1, 5, 9],\n",
       "                  [2, 6, 5]]))[height2(), width()]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "height2 = gensym(int, name=\"height2\")\n",
    "subst(A, {height: height2()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{(\\mathsf{\\vphantom{fg}height},\\mathsf{\\vphantom{fg}width})\\rightarrow\\mathsf{\\vphantom{fg}layer}} = \\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}layer}\\\\\n",
    "\\begin{bmatrix}\n",
    "    3 & 1 & 4 & 1 & 5 & 9 & 2 & 6 & 5\n",
    "\\end{bmatrix}\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    }
   ],
   "source": [
    "layer = gensym(int, name=\"layer\")\n",
    "A_layer = subst(A, {height: layer() // 3, width: layer() % 3})\n",
    "print(subst(A_layer, {layer: 2}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A_{\\mathsf{\\vphantom{fg}layer}\\rightarrow(\\mathsf{\\vphantom{fg}height},\\mathsf{\\vphantom{fg}width})} = \\mathsf{\\vphantom{fg}height}\n",
    "\\begin{array}[b]{@{}c@{}}\\mathsf{\\vphantom{fg}width}\n",
    "\\\\\\begin{bmatrix}\n",
    "  3 & 1 & 4 \\\\\n",
    "  1 & 5 & 9 \\\\\n",
    "  2 & 6 & 5 \\\\\n",
    "\\end{bmatrix}\\end{array}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_torch_op(tensor([[3, 1, 4],\n",
      "        [1, 5, 9],\n",
      "        [2, 6, 5]]), [floordiv(add(mul(height(), 3), mod(width(), 3)), 3), mod(add(mul(height(), 3), mod(width(), 3)), 3)])\n"
     ]
    }
   ],
   "source": [
    "print(subst(A_layer, {layer: height() * 3 + width() % 3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of advanced indexing can be achieved through name substitutions in funsors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}ax}}}{\\vphantom{fg}\\mathrm{index}}} \\colon \\mathbb{R}^{\\mathsf{\\vphantom{fg}ax}[n]} \\times [n] \\rightarrow \\mathbb{R}\\\\\n",
    "\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}ax}}}{\\vphantom{fg}\\mathrm{index}}}(A, i) = A_{\\mathsf{\\vphantom{fg}ax}(i)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "  E &\\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}vocab}[n] \\times \\mathsf{\\vphantom{fg}emb}} \\\\\n",
    "  i &\\in [n] \\\\\n",
    "  I &\\in [n]^{\\mathsf{\\vphantom{fg}seq}} \\\\\n",
    "  P &\\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}seq}\\times \\mathsf{\\vphantom{fg}vocab}[n]}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial indexing $\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}vocab}}}{\\vphantom{fg}\\mathrm{index}}}(E,i)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([1, 3, 7]))[emb()]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab, emb = gensym(int, name=\"vocab\"), gensym(int, name=\"emb\")\n",
    "E = Indexable(\n",
    "    tensor([[2, 1, 5], [3, 4, 2], [1, 3, 7], [1, 4, 3], [5, 9, 2]]),\n",
    ")[vocab(), emb()]\n",
    "\n",
    "subst(E, {vocab: 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer array indexing $\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}vocab}}}{\\vphantom{fg}\\mathrm{index}}}(E,I)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([[1, 4, 3],\n",
       "                  [1, 3, 7],\n",
       "                  [5, 9, 2],\n",
       "                  [2, 1, 5]]))[seq(), emb()]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq = gensym(int, name=\"seq\")\n",
    "I = Indexable(tensor([3, 2, 4, 0]))[seq()]\n",
    "\n",
    "subst(E, {vocab: I})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather operation $\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}vocab}}}{\\vphantom{fg}\\mathrm{index}}}(P,I)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([1, 5, 2, 2]))[seq()]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = Indexable(\n",
    "    tensor([[6, 2, 4, 2], [8, 2, 1, 3], [5, 5, 7, 0], [1, 3, 8, 2], [5, 9, 2, 3]]),\n",
    ")[vocab(), seq()]\n",
    "\n",
    "subst(P, {vocab: I})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing with two integer arrays:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  |\\mathsf{\\vphantom{fg}seq}| &= m \\\\\n",
    "  I_1 &= [m]^\\mathsf{\\vphantom{fg}subseq}\\\\\n",
    "  I_2 &= [n]^\\mathsf{\\vphantom{fg}subseq}\\\\\n",
    "  S &= \\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}vocab}}}{\\vphantom{fg}\\mathrm{index}}}(\\mathop{\\underset{\\substack{\\mathsf{\\vphantom{fg}seq}}}{\\vphantom{fg}\\mathrm{index}}}(P, I_1), I_2) \\in \\mathbb{R}^{\\mathsf{\\vphantom{fg}subseq}} \\\\\n",
    "  S_{\\mathsf{\\vphantom{fg}subseq}(i)} &= P_{\\mathsf{\\vphantom{fg}seq}(I_{\\mathsf{\\vphantom{fg}subseq}(i)}), \\mathsf{\\vphantom{fg}vocab}(I_{\\mathsf{\\vphantom{fg}subseq}(i)})}.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Indexable(tensor([3, 4, 5]))[subseq()]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subseq = gensym(int, name=\"subseq\")\n",
    "I1 = Indexable(tensor([1, 2, 0]))[subseq()]\n",
    "I2 = Indexable(tensor([3, 0, 4]))[subseq()]\n",
    "\n",
    "subst(P, {seq: I1, vocab: I2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
